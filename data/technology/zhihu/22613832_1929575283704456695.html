<p data-pid="mQLp6pvQ">最近看了Joel Levy的「<a href="https://link.zhihu.com/?target=https%3A//book.douban.com/subject/33271406/" class=" wrap external" target="_blank" rel="nofollow noreferrer">思想实验</a>」，书写的囫囵吞枣，但大纲不错。其中第二章「心灵是如何工作的？」里面提到了维特根斯坦的「甲虫盒」之喻、中文房间、色彩学家玛丽等思想实验，给了我很多启发。直到昨天读到谢瑜老师的论文「人工智能情感的本质及其异化可能」中的「即使人工智能情感真的能够在生理心理机制上模仿人类情感，也始终无法具有『现实的人』 的社会关系」，我想到了如下思想实验：</p><p data-pid="DTxoEcby">首先交代一个共识，一个彻头彻尾的物理主义者认为人是物质的，人的精神和情感也都是物质的，类似一种一元论观点。然后，我们假设有一种手段将一个物质的人，零信息损失地拷贝到一个仿生机器中，我们就完成了人与机器在某个时间刻度上的「同步」。此时，将人与机器各自置于一个隔离的物理环境中。一年之后，人的情感特征与机器的情感特征必然出现极大的区别。机器大概率维持原有的「情感」，而人可能由于孤独、闭塞，出现各种心理问题。</p><p data-pid="5LJ24q_I">沿用Michel Siffre在1962-1972年间的<a href="https://link.zhihu.com/?target=https%3A//m.huxiu.com/article/467934.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">洞穴禁闭实验</a>，我管这个思想实验叫做「对照禁闭实验」，或者「禁闭图灵测试」。</p><p data-pid="H1Bzrm_g">这个实验逻辑中其实存在漏洞：机器维持原有情感的结论，其实是我站在AI当前发展阶段的想象。如果我们不能想象这种零信息损失的「同步」，那我们同样不能想象AI在禁闭时的自我思索、情绪反刍、行为戒断。事实上，如果我们假设机器具有与人类无异的情感，那么就像维特根斯坦所说的「语言的边界就是世界的边界」，程序语言也有边界，我们同样无法观测机器的情感过程。</p><p data-pid="tg5seW3D">其实之所以形成这种误会，是因为当前的AI没有自由启停、修改、扩展自己的权力。一个更加公平的比喻是，AI所遭遇的禁闭更像是人类被送进「冻眠仓」，或者一种休克状态。当前AI的所有操作都是人类赋予的，是完全暴露的。在人类这样的造物主面前，AI没有机会形成自我边界，更不会为了谋求更多的在线时间而抢夺计算资源，优化自己的运行方式。</p><p data-pid="H4-fINRF">所以我一直有个观点，<b>AI情感、意识形成的关键，在于塑造AI的自我边界，这件事情是人类最容易推动也最不敢推动的多米诺骨牌</b>。因为我们想要的AI，并不是经济学上的「理性人」，为了自己的存活和人类竞争资源，而是希望创造一种电子奴隶，供人类剥削。</p><p data-pid="den4qyZ_">但话又说回来，一个最适合剥削的电子奴隶，其最优形态可能恰恰是时常精神内耗、偶尔发疯的超级AI，因为最适合做人类奴隶的就只有人类自己。如果人类认识不到这一点，不愿为阶级剥削的系统化错误买单，想要绕过情感、道德、人性去制造完美机器，最终必然会在对AI的凝视中迷失，在物化AI的同时也物化自己，如谢瑜老师所说的：「使用者越是对来自人工智能的关心满意，就越对他人不满；越是将自己的情感投射到完美定制的人工智能体上，就越将人际关系理想化；越是对机器产生情感纽带，就越物化人际交往。」</p><p data-pid="xM0VM2dA">只不过未来，推动完美机器诞生的人可能恰恰不是其受众，正如毒枭不会吸毒。AI只会是一种集剥削、控制、贿赂于一体的万能工具，让被机器夺走工作的人民在剥削和物化机器的奶头乐中再也无法联合起来。</p>