<div>torchvision中dataset和transform方法的配合需要着重注意！<br/><br/>一些dataset，比如MNIST一族，构造函数里调用_load_data返回的是Tensor，而且是uint8的Tensor。在它的__getitem__方法中，在调用用户指定的transform前先转为了PILImage。所以我们的transform中要调用ToTensor得到一个浮点型张量。但如果我们自定义一个dataset类，类内从原始的MNIST类的data变量截获数据，并自定义__getitem__就要注意data中的Tensor需要除以255才能得到等效的结果。<br/> <br/>然而到了CIFAR一族dataset，底层是用pickle直接反序列化得到的值在0到1之间的浮点型numpy数组。所以transform中直接ToTensor就好。<br/><br/>最近抄了FedML框架中的的数据预处理，结果从CIFAR100移植到FashionMNIST的时候训练集和测试集的数据之间差了一个255的归一化，直接导致测试准确率在50%到70%之间飘忽不定。后来逐行增量调试才找到这个问题，所以抄代码如果不确定每一行的意思最好不要随便抄哇。<br/><a class="hash_tag" href="https://www.zhihu.com/topic/20075993" data-pin-topic="zhihu://topic/20075993/pin20">#PyTorch</a> <a class="hash_tag" href="https://www.zhihu.com/topic/19965355" data-pin-topic="zhihu://topic/19965355/pin20">#数据预处理</a> <a class="hash_tag" href="https://www.zhihu.com/topic/19556650" data-pin-topic="zhihu://topic/19556650/pin20">#bug</a> <a class="hash_tag" href="https://www.zhihu.com/topic/19554119" data-pin-topic="zhihu://topic/19554119/pin20">#建议</a> </div><img src="https://pic4.zhimg.com/50/v2-b45e85c6bd0c0e03a7af19f8c944efbd_b.jpg" data-rawwidth="819" data-rawheight="518" class="origin_image zh-lightbox-thumb" width="819" data-original="https://picx.zhimg.com/50/v2-109ea9aa8253d94f149ddd04d60936d7_r.jpg" data-original-src="https://picx.zhimg.com/50/v2-109ea9aa8253d94f149ddd04d60936d7_r.jpg"><img src="https://pic1.zhimg.com/50/v2-6ca6afe712717d348fc313dd664f1ed2_b.jpg" data-rawwidth="804" data-rawheight="460" class="origin_image zh-lightbox-thumb" width="804" data-original="https://pic4.zhimg.com/50/v2-9d83e285a3d05e96e94793d9ca85359b_r.jpg" data-original-src="https://pic4.zhimg.com/50/v2-9d83e285a3d05e96e94793d9ca85359b_r.jpg">