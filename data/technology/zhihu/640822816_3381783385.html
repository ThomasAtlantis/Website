<p data-pid="PGlhwntn">AI大模型元年4月9日，加州大学的奈奈在C站发布自己的LoRA模型，成为全球第一个开源女生，而刑满释放的张三成为下载这个模型的第3356个人。</p><p data-pid="dmENa9Oi">此时他早已改过自新，开始从事普法教育的自媒体运营。本想站在大模型的风口上用AI生成几张插图，结果提示词一个手滑，得到了一些不可描述的图片！</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/50/v2-3f0dab134e2e89779aa59ec9fa466970_720w.jpg?source=c8b7c179" data-caption="" data-size="normal" data-rawwidth="2043" data-rawheight="1280" data-original-token="v2-ede6e76b09594b5fc539a621d221e9ba" data-default-watermark-src="https://picx.zhimg.com/50/v2-bd0327e839ac74be830e0b1dce5fdfd7_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb" width="2043" data-original="https://picx.zhimg.com/v2-3f0dab134e2e89779aa59ec9fa466970_r.jpg?source=c8b7c179"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='2043'%20height='1280'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2043" data-rawheight="1280" data-original-token="v2-ede6e76b09594b5fc539a621d221e9ba" data-default-watermark-src="https://picx.zhimg.com/50/v2-bd0327e839ac74be830e0b1dce5fdfd7_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb lazy" width="2043" data-original="https://picx.zhimg.com/v2-3f0dab134e2e89779aa59ec9fa466970_r.jpg?source=c8b7c179" data-actualsrc="https://picx.zhimg.com/50/v2-3f0dab134e2e89779aa59ec9fa466970_720w.jpg?source=c8b7c179"></figure><p data-pid="5PooEBa7">张三马上想到《中华人民共和国刑法》第三百六十四条规定“传播淫秽的书刊、影片、音像、图片或者其他淫秽物品， 情节严重的，处二年以下有期徒刑、拘役或者管制。”而第三百六十七条规定“本法所称淫秽物品，是指具体描绘性行为或者露骨宣扬色情的诲淫性的书刊、影片、录像带、录音带、图片及其他淫秽物品。”</p><p data-pid="3X9J7SkC">技术知识匮乏的他无法分辨面前图片的真假。<b>“这张图本来就在训练数据里吗？还是我创作了这张图？是她犯了传播淫秽物品罪，还是我？”</b>张三回想起踩缝纫机的日子，不禁一身冷汗。</p><hr><h2>AI创作及其参与者</h2><p data-pid="tRnwFLyS"><b>尽管创作一般特指文学或艺术作品的制造过程，但我认为AI创作的概念不必局限于此。</b></p><p data-pid="LcQTmd0l">以绘画艺术为例。20世纪初的达达运动向艺术创作的传统媒介发起挑战，声称“无论多么平凡，艺术品都可以由任何东西制成”。50年代的波普艺术则从消费者关注的名人肖像、商品品牌等具有视觉冲击力的物品取材，构建通俗、具象、可复制的大众艺术。这些艺术态度或流派试图去除艺术的神圣性，寻找一种更普遍的审美概念，却终究停留为少数人的狂欢。</p><p data-pid="8ExsTJ-9">如今的生成式AI大模型，使用自然语言对话的交互方式，具备多模态内容的处理和生成能力，不仅是创作工具的革命，更是创作过程的革命。如果说波普降低了大众欣赏和理解作品的门槛，那么<b>AI大模型第一次让大众广泛参与到创作过程中</b>。线条、色彩、造型和构图，众多繁杂的技术被自然语言提示词所取代。创作的门槛无限下沉，我们必然会追问一个问题：<b>AI创作的内容是否是艺术品？</b></p><p data-pid="eFJ7LZND">这个发问其实极具诱导性，仿佛既定了创作活动的主体是AI，而将人类排除在外。实际上，<b>AI不能自主创作任何内容</b>，其中必然有人类主观参与的成分，例如模型结构设计、训练数据标注、提示词选择以及一系列复杂的参数控制。下图是开源文生图模型Stable Diffusion的控制界面web UI，这些复杂的提示词和参数只是生成高质量图片所需的冰山一角。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/50/v2-d2e960f142e815ef096ce19cecb13aa6_720w.jpg?source=c8b7c179" data-caption="" data-size="normal" data-rawwidth="1273" data-rawheight="917" data-original-token="v2-a67d37d5327f73847f809d9db06aa643" data-default-watermark-src="https://pica.zhimg.com/50/v2-0940ba23b8f0b59cd694e7d1bb45c033_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb" width="1273" data-original="https://pic1.zhimg.com/v2-d2e960f142e815ef096ce19cecb13aa6_r.jpg?source=c8b7c179"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1273'%20height='917'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1273" data-rawheight="917" data-original-token="v2-a67d37d5327f73847f809d9db06aa643" data-default-watermark-src="https://pica.zhimg.com/50/v2-0940ba23b8f0b59cd694e7d1bb45c033_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb lazy" width="1273" data-original="https://pic1.zhimg.com/v2-d2e960f142e815ef096ce19cecb13aa6_r.jpg?source=c8b7c179" data-actualsrc="https://picx.zhimg.com/50/v2-d2e960f142e815ef096ce19cecb13aa6_720w.jpg?source=c8b7c179"></figure><p data-pid="TgPsAuwO">目前提示词仍然依赖精妙的人工设计，其顺序、权重、用词甚至是大小写和下划线都对结果有着至关重要的影响。此外，基础模型生成草稿后，通常使用一些特定数据集微调过的模块（LoRA）对结果进行修饰润色，类似于滤镜、修容、补细节，奈奈LoRA就是一种定制化的换脸。这类模块依赖训练者刻意设计的关键词“后门”才能触发，而一次创作可能面临十几种模块的加权排列组合。</p><p data-pid="G9oa7hqh">有人可能质疑，这种“提示词工程”不过是强人工智能到来前的苟且，未来必然有一种技术使用零参数和完全自然的语言控制，到那时总该是AI创作了。其实不然，<b>我们还忽略了AI创作极其重要的一环，人类的审美反馈</b>，即我们有擦除部分或全部结果并勒令AI重新创作的权力。</p><p data-pid="RXH_ZwIk">埃米尔·博雷尔在1909年提出<b>无限猴子定理：</b>“让一只猴子在<span class="nolink">打字机</span>上<span class="nolink">随机</span>地按键，当按键时间达到<span class="nolink">无穷</span>时，<span class="nolink">几乎必然</span>能够打出任何给定的文字”。<b>AI不过是一只受过训练的“高级猴子”</b>，有本庞大的词典，输出的词汇组合碰巧命中人类用语习惯下的统计概率时被赋予了香蕉。如果AI生成了一本莎士比亚全集，一定是人类认出了那是莎士比亚全集。或者说，是人类的审美反馈，在训练和推理期间，从AI的胡言乱语中认出了艺术性。</p><p data-pid="pkgLV5ak"><b>判定性问题总是轻易的，而生成性问题可以看做是NP难度。</b>AI的伟大在于，将猴子打字所需的无限时间压缩在近乎实时的范围内：软件上我们让AI有更好的条件反射，硬件上在处理器上万个核心中各跑一些猴子。这种实时性让AI成为笔刷而不是画家，我们每画一笔就可以加以审视和修改，如此，形成创作闭环的全过程。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/50/v2-2fadf28f954219728aa49cdbcd5eda96_720w.jpg?source=c8b7c179" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="196" data-original-token="v2-59e7599d6d9a08c444f8310b7044cb4a" data-default-watermark-src="https://picx.zhimg.com/50/v2-a30a6ab5e59f167ceb6aec491b1c2dc4_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb" width="640" data-original="https://picx.zhimg.com/v2-2fadf28f954219728aa49cdbcd5eda96_r.jpg?source=c8b7c179"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='640'%20height='196'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="196" data-original-token="v2-59e7599d6d9a08c444f8310b7044cb4a" data-default-watermark-src="https://picx.zhimg.com/50/v2-a30a6ab5e59f167ceb6aec491b1c2dc4_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb lazy" width="640" data-original="https://picx.zhimg.com/v2-2fadf28f954219728aa49cdbcd5eda96_r.jpg?source=c8b7c179" data-actualsrc="https://picx.zhimg.com/50/v2-2fadf28f954219728aa49cdbcd5eda96_720w.jpg?source=c8b7c179"></figure><p data-pid="R7691hW0">假如某天艺术批评家再无法分辨AI创作，像自由人文主义所倡导的“文本细读”那样，“能够超越作者的时代特性和局限，而直接同人性中恒定不变的内容对话”，此时具备艺术性的AI作品就会脱颖而出，其中蕴含的必定是人类闭环调节过程中付出的努力和付诸的情感。AI作品的艺术性归根结底是人赋予的艺术性，所以《刑法》第三百六十七条所说的“<b>包含有色情内容的有艺术价值的文学、艺术作品不视为淫秽物品</b>”便可以举证。</p><p data-pid="5XlxYLtq">AI创作不局限在文学艺术作品，以上既论证了狭义上AI作为“高级猴子”无法创作作品，又展示了广义上人类闭环调节使得最终的结果成为作品。其实，艺术本身的价值就是在现实生活之外开辟一个由想象构建的精神游乐场或避难所，艺术作品中的虚构和夸张慰藉人们对抗生命有限性时的沮丧和迷茫。AI颠覆了艺术的媒介，也改写了艺术传达和交互的形式。一个训练精妙的AI模型，让用户如此惊喜赞叹，其本身又何尝不是一种艺术品？</p><p data-pid="1I88zau2">总结一下以上论证中AI创作过程的参与者：<b>1）包含计算机学者、工程师在内的AI软硬件基础设施的缔造者；2）包含众包数据标注师、广大网民和画师的训练数据供给者；</b>3）筛选数据并预训练基础模型的AI工程师；4）在特定数据集定制化训练修饰模块的AI开源社区成员；<b>5）利用提示词工程和调参工程生产内容的AI模型使用者；</b>6）AI模型使用者打包发布的AI应用的下游用户。</p><p data-pid="dIsVONVl">其中1、2、5是大众视域下的常见角色。</p><h2>AI创作的伦理风险</h2><p data-pid="-Ye1Gscr"><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/o1N7SHbDb_qRmya-9bMhyA" class=" wrap external" target="_blank" rel="nofollow noreferrer">《互联网是人类历史的一段弯路吗》</a>指出网络使“<b>风险生产者的门槛降低，而风险受害者的规模和频次上升。</b>”AI大模型将创作门槛下沉到有史以来的最低点，加之以模型不可解释、内容以假乱真的特点，为互联网伦理风险的扩散推波助澜。</p><h3>1 深度伪造</h3><p data-pid="SnUxaCdT">2019年，陌陌旗下的一款名叫“ZAO”的换脸APP在各大社交网络刷屏。它仅需用户上传一张正脸照，就可以换脸到指定的电影或视频片段。9月时因涉嫌过度攫取用户授权而被工信部约谈（见第5点），同时也为社会展示了利用AI手段侵犯肖像权的可能。</p><p data-pid="vROEsT4z">2021年演员刘昊然被换脸到淫秽视频中并在互联网上进行传播，引发舆论关注。工作室在事发后不久，向警方报案。这次事件并不是偶然，也不是黑客有意操纵，因为<b>AI换脸技术早已形成成熟的开源社区</b>，比如事发前2020年开源的<a href="https://zhuanlan.zhihu.com/p/145800706" class="internal" target="_blank">DeepFaceLab</a>就提供了一种傻瓜式的整合工具包。</p><p data-pid="i0u9H0S_">除了将明星肖像换到色情视频上，另一个显而易见的违法思路就是用AI将正常视频脑补成色情视频。罗老师有期<a href="https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1RY411p7Yq/%3Fvd_source%3D9ec8ecdae4f49859064ef9db5136146c" class=" wrap external" target="_blank" rel="nofollow noreferrer">视频</a>讨论了这种AI脱衣网站，并介绍了2019年美国众议院提出的《深度伪造责任法案》。该法案要求任何创建深度伪造视频媒体文件的人，必须用“不可删除的数字水印以及文本描述”来说明该媒体文件是篡改或生成的，否则将属于犯罪行为，刑事责任认定最高五年有期徒刑。</p><p data-pid="Y62NUWJ4"><b>AI大模型将“换脸”和“换身体”两种路线结合在一起，让创作变得更简单、风险变得更复杂</b>。例如本文提到的奈奈LoRA，最少只需要几十张图片做训练（参考妙鸭相机），遵循通用的数据结构，像插件一样可以被下载、传播和使用。承载肖像的介质从图片置换成模型，它不再像贴图一样把肖像覆盖在面部合适位置，而是直接生成出你想要的任意角度、表情、光线、肤色，你甚至可以把两个人的肖像按照权重进行混合。这使得伪造的内容更加难以辨别，也更难取证。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/50/v2-c63634b2004b81bc348fcc1d9a5073de_720w.jpg?source=c8b7c179" data-caption="" data-size="normal" data-rawwidth="2434" data-rawheight="1345" data-original-token="v2-9f20f40a5a0f99f9ca7adf8aed89b2c9" data-default-watermark-src="https://pica.zhimg.com/50/v2-ca520e2496c2d2d3e2d8b4c654fa5d17_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb" width="2434" data-original="https://pic1.zhimg.com/v2-c63634b2004b81bc348fcc1d9a5073de_r.jpg?source=c8b7c179"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='2434'%20height='1345'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2434" data-rawheight="1345" data-original-token="v2-9f20f40a5a0f99f9ca7adf8aed89b2c9" data-default-watermark-src="https://pica.zhimg.com/50/v2-ca520e2496c2d2d3e2d8b4c654fa5d17_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb lazy" width="2434" data-original="https://pic1.zhimg.com/v2-c63634b2004b81bc348fcc1d9a5073de_r.jpg?source=c8b7c179" data-actualsrc="https://pic1.zhimg.com/50/v2-c63634b2004b81bc348fcc1d9a5073de_720w.jpg?source=c8b7c179"></figure><h3>2 夹带私货</h3><p data-pid="Kxabovoz">在文生图模型的负面提示词中经常能看到“NSFW”这个缩略语，全称是“Not Safe For Watch”，这暗示着<b>模型可能具备生成非法内容的能力</b>。而非法内容包括但不限于错误、偏见、违法和侮辱性的言论、图片和音视频。</p><p data-pid="Tvs3kYcE">在学术界有一种流行的观点：AI大模型实际上是一个数据压缩算法，把互联网爬取的海量数据压缩在有限的模型参数中，而我们和大模型对话的过程就是用自然语言查询这种压缩数据库的过程。换句话说，大模型浓缩了知识。将非法内容比作蟑螂，当我们看到一只蟑螂，暗处已经有无数只。</p><p data-pid="Zl5ZRR2e">互联网爬取的数据质量参差不齐，巨大的体量也不容开发者逐一审查。当我们看到大模型时不时生成一些非法内容，就好比自家小孩儿不知道在哪学会了爆粗口，让大人又生气又惊讶。</p><p data-pid="ZuLq3Usx">举个简单的例证，利用英文互联网的图片数据训练得到的基础模型，不加额外的关键词约束，可以轻松地生成富于审美刻板印象的中国面孔。我觉得这个例子比所谓的种族歧视言论更加有力，因为很多时候<b>大模型的夹带私货是隐形的，是具备意识形态的，这也是中国要有国产大模型的原因</b>。</p><p data-pid="f-5NEoKe">在23年初，我时常讨论“文化污染”的现象，即大模型将吐出来的内容又吃回去，导致网络中主流文化吞并非主流文化的现象。当训练数据的大多数成为暴力的大多数，那么大模型何尝不是一种助纣为虐？</p><p data-pid="xFZp9weh">当具有纯粹人类血统的数据越来越少以至枯竭，我们恐怕再不能拥有曾经那种多元、包容的网络讨论。而当具身智能将AI作品生成的能力用在策略生成上，将人类从旁观者带入为承受作用的客体，这种被忽视的隐性文化将成为杀死我们的利刃。</p><h3>3 电子水军</h3><p data-pid="QRMqbDic">20年我曾在社交平台做过一个实验，发现为陌生用户的动态点赞有概率获得个人主页的曝光量。于是，通过简单的爬虫技术制作了一个点赞机器人，在名不见经传的小平台1天收获了300粉丝。这种事情其实并不局限在实验层面，而是在各个社交平台每时每刻都在发生。</p><p data-pid="8-6RvQAj">如今AI模型的生成能力完全可以将这种僵尸机器人包装地更具“人性”。微博上有人调侃僵尸号动态里的文字抽象、忧郁，比某些诗人的诗歌更像诗，戏称“僵尸文学”。而与此同时，AI模型生成虚假信息用于开发调试的Mock技术正蓬勃发展。<b>AI不仅可以生成难以分辨的动态内容，甚至可以维持一个固定的人设</b>，有自己的MBTI（参考<a href="https://zhuanlan.zhihu.com/p/663943384" class="internal" target="_blank">这里</a>。</p><figure data-size="normal"><noscript><img src="https://pica.zhimg.com/50/v2-ab2d5645a6cb3ccc2d8bbee3eedf6936_720w.jpg?source=c8b7c179" data-caption="" data-size="normal" data-rawwidth="392" data-rawheight="128" data-original-token="v2-073c9708209d249055ac9af67bc7288e" data-default-watermark-src="https://picx.zhimg.com/50/v2-f712f50ed2793b5e5ae1653372f88193_720w.jpg?source=c8b7c179" class="content_image" width="392"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='392'%20height='128'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="392" data-rawheight="128" data-original-token="v2-073c9708209d249055ac9af67bc7288e" data-default-watermark-src="https://picx.zhimg.com/50/v2-f712f50ed2793b5e5ae1653372f88193_720w.jpg?source=c8b7c179" class="content_image lazy" width="392" data-actualsrc="https://pica.zhimg.com/50/v2-ab2d5645a6cb3ccc2d8bbee3eedf6936_720w.jpg?source=c8b7c179"></figure><p data-pid="AM4_qTpI">在可以预见的未来，我们必将遭遇更加真实的“电子水军”，而它们是被用于商业操纵还是颜色革命就不得而知。回顾上面大模型夹带私货的特点，有一类工作专门研究如何通过“<a href="https://zhuanlan.zhihu.com/p/624208064" class="internal" target="_blank">数据投毒</a>”让大模型刻意生成一些非法内容。而对于水军而言，个体言论不需要那么“语不惊人死不休”，只需要让模型们的言论交叉佐证，就足以操纵互联网的舆论导向。</p><p data-pid="OVnVR0yL">AI加持的电子水军必然对审查系统提出更高的要求。但比较矛盾的是，<b>图灵测试要求AI表现地与人类一致，而对电子水军的审查却要求我们分辨哪些AI不是真人</b>。在学术界，这种生成器和判别器的对抗训练，往往以判别器失败作为收敛的结局。但换个角度想，如果我们真的运用比生成式AI更强的判别模型来进行审查，那时的互联网环境可能又大不一样。</p><h3>4 内容剽窃</h3><p data-pid="pCBIdZMG">2023年，正值文生图模型DALL-E 3、Midjourney和Stable Diffusion三足鼎立，有个画师朋友来和我讨论AI绘图。她并没有指责AI抢夺了工作资源，而是矛头直指内容剽窃现象。</p><p data-pid="PiBwmmA4">上文提到AI大模型的训练数据大多通过网络爬虫获取。GPT-2使用了45GB的数据，而到GPT-3数据量就暴涨到45TB。<b>在这些海量的数据中，大多数是没有经过版权校验的，而训练得到的大模型却被公司用于商业盈利。</b></p><p data-pid="eNhy7qvp">比较有名的例子是《纽约时报》诉讼Microsoft和OpenAI案。《纽约时报》在诉讼中说，“通过Microsoft的Bing Chat和OpenAI的ChatGPT，被告试图未经许可或付款而使用《纽约时报》的文章。”回想一下目前AI大模型加持的搜索引擎，它们在回答计算机相关技术问题时，会“引经据典”，而那些被引用的博客文章的作者是否赋予了它们如此的权力呢？</p><p data-pid="XF0pyBJY">我所研究的联邦学习方向关注如何在不收集用户原始数据的情况下训练模型，而现实中人们的隐私需求只会更高：我们不仅不希望模型拿到训练数据，也不希望它具有输出这类内容的能力。<b>如何避免某些数据被大模型学到，或者说如何让已经学到这些数据的大模型忘掉它们？</b>学术界将这个问题称作“<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1912.03817" class=" wrap external" target="_blank" rel="nofollow noreferrer">Machine Unlearning</a>”。目前的工作运用了复杂的数学理论推导，但仍然效果不佳。</p><p data-pid="JiLP9Tey">如果无法完全避免模型的剽窃，是否有办法监管和限制这类事情的发生？这就涉及到数据确权和溯源，而这也有一个专门的研究方向。大模型所用的神经网络不像是工业流水线上的机器，拆开可以清楚地看到传动结构。给训练数据打上水印，一番训练之后，输出的内容就自动把水印抹去了。所以这个领域要研究如何给数据做标记，让输出的内容中仍然能检测出这种标记，以便取证。</p><p data-pid="JAccgR-2">现实的情况会更加复杂。如果一个基础模型并没有侵权，但在这个模型上进行二次开发的工程师掺入了一些敏感数据进行重训练，那么如何判定侵权行为的主体？所以也有一部分工作研究如何给模型本身打上水印，在模型被下载、传播和篡改时不被抹掉。</p><h3>5 隐私泄露</h3><p data-pid="1AyRqov6">上文提到ZAO被约谈，是因为它的用户协议中有这样一句话：“在您上传及/或发布用户内容以前,您同意或者确保实际权利人同意授予ZAO及其关联公司以及ZAO用户全球范围内完全免费、不可撤销、永久、可转授权和可再许可的权利。”形象地说，就是当你上传一张正面的人像后，公司可以把你的人脸据为己有或者转让。</p><p data-pid="9lXnK72J">很难想象这样的数据会被用于何处，毕竟对抗攻击像人脸识别这样广泛应用的技术并不难。2019年有美国公司使用了DeepFake技术欺骗了支付宝和微信的支付程序，并可以顺利通过机场等自助终端的检验。可以用于人脸识别，那么它也同样可以用于高级电信诈骗，实时换脸来勒索你的家人。</p><p data-pid="2BWhq9iK">2024年AI应用发展的一大趋势，就是手机厂商倾向于开发<a href="https://www.zhihu.com/question/638894116/answer/3357196534" class="internal" target="_blank">融合大模型能力的操作系统</a>，作为用户和应用交互的桥梁。说是桥梁，其实更像是拦河大坝，拦截流量和数据，发出电、生出钱。而操作系统可以访问到的数据可就不仅仅是相册的图片了，它可以录音、拍照、截屏，读取聊天记录、短信、邮件，甚至根据三轴加速度计判断用户的活动。这意味着<b>在操作系统级别的AI大模型面前，用户没有任何隐私可言</b>，毕竟隐私就是用来交换便利性的货币。</p><p data-pid="vE7FgUK-">除了训练数据的隐私性，网上的文章大多忽视了另一个层面的问题：提示词隐私。我们用自然语言而不是按键、滚动轴和大模型交互，<b>和大模型对话本身就是隐私的，可能很多和父母伴侣都难以启齿的私密问题我们会和AI讨论</b>。大模型是现学现卖的，在GPT公测初期，我们可以看到一个人给模型的反馈很快被吸收消化，不知何时就出现在大洋彼岸模型给另一个人的回答中。</p><h2>AI创作必然受伦理约束</h2><p data-pid="b1FMBafL">伦理是指在处理人与人、人与社会相互关系时应遵循的道理和准则，AI创作过程无法排除人的参与而独立存在，AI创作所表达的也是人的意志和情感，所以必然也要遵循现有的伦理约束。但另一方面，现有的伦理或法律系统在某些复杂的AI创作问题上显得捉襟见肘。为了不妨害AI大模型技术和相关经济市场的繁荣，法律也必然会权衡这些伦理问题的危害性。</p>