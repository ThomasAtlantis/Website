<p data-pid="jN0ciBNe">本文参考了CSDN这篇博客：<a href="http://link.zhihu.com/?target=https%3A//blog.csdn.net/sun5966769/article/details/89558088" class=" wrap external" target="_blank" rel="nofollow noreferrer">Hadoop 3.2.0安装</a>，感谢博主的分享~</p><h2>试用华为云耀服务器并建立通信</h2><p data-pid="9cupBAN8">注册并登录<a href="http://link.zhihu.com/?target=https%3A//activity.huaweicloud.com/free_test/index.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">华为云官网</a>，在为您推荐中选择0元试用1核2G云耀服务器</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-11e953830102644449ff848372dca1c0_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1291" data-rawheight="495" class="origin_image zh-lightbox-thumb" width="1291" data-original="https://pic1.zhimg.com/v2-11e953830102644449ff848372dca1c0_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1291'%20height='495'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1291" data-rawheight="495" class="origin_image zh-lightbox-thumb lazy" width="1291" data-original="https://pic1.zhimg.com/v2-11e953830102644449ff848372dca1c0_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-11e953830102644449ff848372dca1c0_720w.jpg?source=d16d100b"></figure><p data-pid="-N6pYgm_">我们就选择预装默认的Ubuntu系统，安全组类型好像选的<code>fully access</code>。付款后我们可以试用1个月。进入<a href="http://link.zhihu.com/?target=https%3A//console.huaweicloud.com/console/%3Fregion%3Dcn-east-3%23/home" class=" wrap external" target="_blank" rel="nofollow noreferrer">控制台</a>，点击下图右上角的查看更多资源</p><figure data-size="normal"><noscript><img src="https://pica.zhimg.com/v2-63dca6d710f1d1beb8e0ff7cd7ca86f3_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1381" data-rawheight="323" class="origin_image zh-lightbox-thumb" width="1381" data-original="https://picx.zhimg.com/v2-63dca6d710f1d1beb8e0ff7cd7ca86f3_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1381'%20height='323'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1381" data-rawheight="323" class="origin_image zh-lightbox-thumb lazy" width="1381" data-original="https://picx.zhimg.com/v2-63dca6d710f1d1beb8e0ff7cd7ca86f3_720w.jpg?source=d16d100b" data-actualsrc="https://pica.zhimg.com/v2-63dca6d710f1d1beb8e0ff7cd7ca86f3_720w.jpg?source=d16d100b"></figure><p data-pid="oh4j1nLM">选择最下方刚刚创建好的服务器，进行管理（付款后服务器资源正在创建，需要等待一段时间，大概3分钟）</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-ce988f11f0d1b94c5384afdd6de33aaa_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1614" data-rawheight="548" class="origin_image zh-lightbox-thumb" width="1614" data-original="https://picx.zhimg.com/v2-ce988f11f0d1b94c5384afdd6de33aaa_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1614'%20height='548'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1614" data-rawheight="548" class="origin_image zh-lightbox-thumb lazy" width="1614" data-original="https://picx.zhimg.com/v2-ce988f11f0d1b94c5384afdd6de33aaa_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-ce988f11f0d1b94c5384afdd6de33aaa_720w.jpg?source=d16d100b"></figure><p data-pid="jU2JyUDk">这时点击下图中的返回（这步操作也是太隐秘了）</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-8a10c6b412731f956a16b27fa7885ac2_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1918" data-rawheight="470" class="origin_image zh-lightbox-thumb" width="1918" data-original="https://picx.zhimg.com/v2-8a10c6b412731f956a16b27fa7885ac2_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1918'%20height='470'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1918" data-rawheight="470" class="origin_image zh-lightbox-thumb lazy" width="1918" data-original="https://picx.zhimg.com/v2-8a10c6b412731f956a16b27fa7885ac2_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-8a10c6b412731f956a16b27fa7885ac2_720w.jpg?source=d16d100b"></figure><p data-pid="bE9C4I2K">在云耀云服务器的管理界面选择重置密码，因为服务器刚创建是没有密码的，没法登录</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-06efcc690096a3bca2163b69ffd06cd6_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="537" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://picx.zhimg.com/v2-06efcc690096a3bca2163b69ffd06cd6_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1920'%20height='537'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="537" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://picx.zhimg.com/v2-06efcc690096a3bca2163b69ffd06cd6_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-06efcc690096a3bca2163b69ffd06cd6_720w.jpg?source=d16d100b"></figure><p data-pid="WX7czYqj">创建密码后，我们就可以使用ssh登录了：</p><div class="highlight"><pre><code class="language-bash"><span></span>ssh root@121.36.X.X
</code></pre></div><p data-pid="lyvPWjKz">然后我们将本地的ssh公钥拷贝到服务器上，复制粘贴即可：</p><div class="highlight"><pre><code class="language-bash"><span></span>cat ~/.ssh/id_rsa.pub
vim ~/.ssh/authorized_keys
</code></pre></div><p data-pid="QIqwL7F_">之后本地就可以ssh免密登录了</p><h2>配置Hadoop伪集群环境</h2><h3>下载Hadoop</h3><p data-pid="D-plg2qp">创建文件夹用来存放Hadoop的库文件</p><div class="highlight"><pre><code class="language-bash"><span></span>mkdir /usr/local/software <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /usr/local/software
</code></pre></div><p data-pid="QBoPK_v_">从Apache的镜像网站下载最新版Hadoop</p><div class="highlight"><pre><code class="language-bash"><span></span>wget https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz
</code></pre></div><p data-pid="bGyB9MGT">解压得到<code>hadoop-3.3.1</code>文件夹</p><div class="highlight"><pre><code class="language-bash"><span></span>tar -zxf hadoop-3.3.1.tar.gz
</code></pre></div><h3>修改主机名</h3><p data-pid="s8FE4q9l">修改主机名为<code>node0</code>，你也可以起别的名字，比如<code>master</code>，但是要记住</p><div class="highlight"><pre><code class="language-bash"><span></span>hostnamectl set-hostname node0
</code></pre></div><p data-pid="BLWNEiZp">查看一下是否修改成功</p><div class="highlight"><pre><code class="language-bash"><span></span>hostname
</code></pre></div><p data-pid="EAiBnphZ">推出账户并重新登录，主机名的修改才能在命令提示符中生效</p><div class="highlight"><pre><code class="language-bash"><span></span><span class="nb">exit</span>
ssh root@121.36.X.X
</code></pre></div><h3>网络与防火墙</h3><p data-pid="3sASfh_X">查看一下服务器的内网IP地址</p><div class="highlight"><pre><code class="language-bash"><span></span>ifconfig <span class="p">|</span> grep <span class="s2">"inet"</span>
</code></pre></div><p data-pid="U_5f2Vz4">修改hosts文件，在文件末尾加上node0</p><div class="highlight"><pre><code class="language-bash"><span></span>vim /etc/hosts
<span class="o">===================</span>
<span class="m">192</span>.168.0.216 node0
</code></pre></div><p data-pid="SWM6UoIx">安装防火墙服务（我不确定这里是不是不安装就不用关</p><div class="highlight"><pre><code class="language-bash"><span></span>apt install firewalld
</code></pre></div><p data-pid="KDmadBOs">查看防火墙状态，这时应该自动启动了，然后关闭防火墙，检查是否关闭</p><div class="highlight"><pre><code class="language-bash"><span></span>systemctl status firewalld
service firewalld stop
systemctl status firewalld
</code></pre></div><h3>安装并配置Java8环境</h3><p data-pid="Yuk71oyZ">我使用的是默认安装方法，你也可以自定义安装，指定安装路径</p><div class="highlight"><pre><code class="language-bash"><span></span>apt install openjdk-8-jdk
</code></pre></div><p data-pid="lJpY_Hgt">测试是否安装成功</p><div class="highlight"><pre><code class="language-bash"><span></span>java -version
</code></pre></div><p data-pid="rAjw0Dv0">修改root用户下的环境变量</p><div class="highlight"><pre><code class="language-bash"><span></span>vim /etc/profile
<span class="o">===================================================</span>
<span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/lib/jvm/java-8-openjdk-amd64
<span class="nb">export</span> <span class="nv">JRE_HOME</span><span class="o">=</span><span class="si">${</span><span class="nv">JAVA_HOME</span><span class="si">}</span>/jre
<span class="nb">export</span> <span class="nv">CLASSPATH</span><span class="o">=</span>.:<span class="si">${</span><span class="nv">JAVA_HOME</span><span class="si">}</span>/lib:<span class="si">${</span><span class="nv">JRE_HOME</span><span class="si">}</span>/lib
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">JAVA_HOME</span><span class="si">}</span>/bin:<span class="nv">$PATH</span>
<span class="nb">export</span> <span class="nv">HADOOP_CLASSPATH</span><span class="o">=</span><span class="si">${</span><span class="nv">JAVA_HOME</span><span class="si">}</span>/lib/tools.jar
<span class="o">===================================================</span>
<span class="nb">source</span> /etc/profile
</code></pre></div><p data-pid="jN5STroS">查看我们配置的<code>JAVA_HOME</code>是否生效</p><div class="highlight"><pre><code class="language-bash"><span></span>which java
---------------------------------------------------
/usr/lib/jvm/java-8-openjdk-amd64/bin/java
</code></pre></div><h3>配置Hadoop环境参数</h3><p data-pid="Lbkg03ZC">进入Hadoop安装目录</p><div class="highlight"><pre><code class="language-bash"><span></span><span class="nb">cd</span> /usr/local/software/hadoop-3.3.1
</code></pre></div><ul><li data-pid="woKMPpZo">你先这样#1</li></ul><div class="highlight"><pre><code class="language-bash"><span></span>vim etc/hadoop/hadoop-env.sh
<span class="o">==================================================</span>
<span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/lib/jvm/java-8-openjdk-amd64
</code></pre></div><ul><li data-pid="FzXUBaax">你再这样#2</li></ul><p data-pid="H3r3Px-7">注意这里的名字奥，node0改成你自己的主机名</p><div class="highlight"><pre><code class="language-bash"><span></span>vim etc/hadoop/core-site.xml
<span class="o">===========================================</span>
&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://node0:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/root/hadoop-runtime/tmp&lt;/value&gt;
&lt;/property&gt;
</code></pre></div><p data-pid="HNPxBV7_">这里别忘了创建这个文件夹，作为hadoop运行时储存文件的地方</p><div class="highlight"><pre><code class="language-bash"><span></span>mkdir -vp /root/hadoop-runtime/tmp
</code></pre></div><ul><li data-pid="A1CtLW7p">你再这样#3</li></ul><div class="highlight"><pre><code class="language-bash"><span></span>vim etc/hadoop/hdfs-site.xml
<span class="o">================================</span>
&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
</code></pre></div><ul><li data-pid="rC8YCTN9">你再这样#4</li></ul><div class="highlight"><pre><code class="language-bash"><span></span>vim etc/hadoop/mapred-site.xml
<span class="o">=========================================</span>
&lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME<span class="o">=</span>/usr/local/software/hadoop-3.3.1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.map.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME<span class="o">=</span>/usr/local/software/hadoop-3.3.1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME<span class="o">=</span>/usr/local/software/hadoop-3.3.1&lt;/value&gt;
&lt;/property&gt;
</code></pre></div><ul><li data-pid="pRzyA7Bx">你再这样#5</li></ul><div class="highlight"><pre><code class="language-bash"><span></span>vim etc/hadoop/yarn-site.xml
<span class="o">==============================================</span>
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;node0&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
</code></pre></div><ul><li data-pid="Gepahx4t">你再这样#6</li></ul><div class="highlight"><pre><code class="language-bash"><span></span>vim /etc/profile
<span class="o">====================================================</span>
<span class="nb">export</span> <span class="nv">HADOOP_HOME</span><span class="o">=</span>/usr/local/software/hadoop-3.3.1
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$HADOOP_HOME</span>/bin:<span class="nv">$HADOOP_HOME</span>/sbin
<span class="o">====================================================</span>
<span class="nb">source</span> /etc/profile
</code></pre></div><ul><li data-pid="0C2vmabR">你还得这样#7</li></ul><p data-pid="qtdGYnC9">对namenode进行格式化</p><div class="highlight"><pre><code class="language-bash"><span></span>hdfs namenode -format
------------------------------------------------------------------------------------
...
Storage directory /root/hadoop-runtime/tmp/dfs/name has been successfully formatted.
...
</code></pre></div><ul><li data-pid="qRaL6cuo">最后还得这样#8</li></ul><p data-pid="Xu5Yboi6">进入<code>sbin</code>文件夹，</p><p data-pid="pXM7fpOF">在<code>start-dfs.sh</code>、<code>stop-dfs.sh</code>顶部添加以下：</p><div class="highlight"><pre><code class="language-bash"><span></span><span class="nv">HDFS_DATANODE_USER</span><span class="o">=</span>root
<span class="nv">HADOOP_SECURE_DN_USER</span><span class="o">=</span>hdfs
<span class="nv">HDFS_NAMENODE_USER</span><span class="o">=</span>root
<span class="nv">HDFS_SECONDARYNAMENODE_USER</span><span class="o">=</span>root
</code></pre></div><p data-pid="zvhDN14g">在<code>start-yarn.sh</code>、<code>stop-yarn.sh</code>顶部添加以下：</p><div class="highlight"><pre><code class="language-bash"><span></span><span class="nv">YARN_RESOURCEMANAGER_USER</span><span class="o">=</span>root
<span class="nv">HADOOP_SECURE_DN_USER</span><span class="o">=</span>yarn
<span class="nv">YARN_NODEMANAGER_USER</span><span class="o">=</span>root
</code></pre></div><h3>配置免密登录</h3><p data-pid="tUU_KA6-">上面我们已经配置过本机登录服务器的免密登录，这里还要配置一下root登录它自己的免密登录，不信你可以试试</p><div class="highlight"><pre><code class="language-bash"><span></span>ssh root@node0
</code></pre></div><p data-pid="ai7JbawX">是需要密码的。接下来我们配置免密</p><div class="highlight"><pre><code class="language-bash"><span></span>ssh-keygen -t rsa -P <span class="s1">''</span> -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
chmod <span class="m">0600</span> ~/.ssh/authorized_keys
</code></pre></div><h2>启动Hadoop服务</h2><p data-pid="PZhf0uNi">进入<code>sbin</code>目录，运行</p><div class="highlight"><pre><code class="language-bash"><span></span>./start-all.sh
------------------------------------
Starting namenodes on <span class="o">[</span>node0<span class="o">]</span>
Starting datanodes
Starting secondary namenodes <span class="o">[</span>node0<span class="o">]</span>
Starting resourcemanager
Starting nodemanagers
</code></pre></div><p data-pid="qkpFX6S1">我们查看一下端口占用情况</p><div class="highlight"><pre><code class="language-bash"><span></span>netstat -tunlp<span class="p">|</span>grep <span class="m">8088</span>
-----------------------------------------------------------------------------------------
tcp        <span class="m">0</span>      <span class="m">0</span> <span class="m">192</span>.168.0.216:8088      <span class="m">0</span>.0.0.0:*               LISTEN      <span class="m">6674</span>/java


netstat -tunlp<span class="p">|</span>grep <span class="m">9870</span>
-----------------------------------------------------------------------------------------
tcp        <span class="m">0</span>      <span class="m">0</span> <span class="m">0</span>.0.0.0:9870            <span class="m">0</span>.0.0.0:*               LISTEN      <span class="m">5971</span>/java
</code></pre></div><p data-pid="tfwEl53z">我们发现HDFS管理界面的默认端口9870是对所有IP监听的，而<code>Resource Manager</code>管理界面的默认端口8088只对局域网IP监听。接下来我们重新开一个终端，使用以下命令创建两个ssh隧道（端口映射）：</p><div class="highlight"><pre><code class="language-bash"><span></span>ssh root@121.36.X.X -L <span class="m">9870</span>:127.0.0.1:9870 -f -N
ssh root@121.36.X.X -L <span class="m">8088</span>:192.168.0.216:8088 -f -N
</code></pre></div><p data-pid="JDdALWbz">使用浏览器访问<code>localhost:9870</code> </p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-6ae1fd376c746ba506dd27aadb70f5b5_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="413" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pic1.zhimg.com/v2-6ae1fd376c746ba506dd27aadb70f5b5_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1920'%20height='413'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="413" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://pic1.zhimg.com/v2-6ae1fd376c746ba506dd27aadb70f5b5_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-6ae1fd376c746ba506dd27aadb70f5b5_720w.jpg?source=d16d100b"></figure><p data-pid="4mXqKPDS">使用浏览器访问<code>localhost:8088</code> </p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-4dee72c01f96e00961bd12784cf52f11_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="550" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pic1.zhimg.com/v2-4dee72c01f96e00961bd12784cf52f11_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1920'%20height='550'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="550" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://pic1.zhimg.com/v2-4dee72c01f96e00961bd12784cf52f11_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-4dee72c01f96e00961bd12784cf52f11_720w.jpg?source=d16d100b"></figure><p data-pid="esMj-6M1">大功告成！如果要关闭服务可以运行</p><div class="highlight"><pre><code class="language-bash"><span></span>./stop-all.sh
------------------------------------
Stopping namenodes on <span class="o">[</span>node0<span class="o">]</span>
Stopping datanodes
Stopping secondary namenodes <span class="o">[</span>node0<span class="o">]</span>
Stopping nodemanagers
Stopping resourcemanager
</code></pre></div><hr><h2>使用MapReduce进行词频统计</h2><p data-pid="mBN1IiLv">参考3.3.1版本Hadoop的官方文档：<a href="http://link.zhihu.com/?target=http%3A//hadoop.apache.org/docs/r3.3.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">MapReduce Tutorial</a>。</p><p data-pid="Y8-56b8r">保证你的Hadoop服务已经启动，且各项环境参数配置准确。新建一个工程文件夹并进入它，我这里使用的是：</p><div class="highlight"><pre><code class="language-bash"><span></span>mkdir /usr/local/workspace <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /usr/local/workspace
</code></pre></div><p data-pid="YYkXQI43">在当前文件夹下新建一个<code>WordCount.java</code>文件：</p><div class="highlight"><pre><code class="language-java"><span></span><span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">java.util.StringTokenizer</span><span class="p">;</span>

<span class="kn">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.Path</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.IntWritable</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.io.Text</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.Job</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.Mapper</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.Reducer</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.lib.input.FileInputFormat</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.mapreduce.lib.output.FileOutputFormat</span><span class="p">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WordCount</span> <span class="p">{</span>

  <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">TokenizerMapper</span>
       <span class="kd">extends</span> <span class="n">Mapper</span><span class="o">&lt;</span><span class="n">Object</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">IntWritable</span><span class="o">&gt;</span><span class="p">{</span>

    <span class="kd">private</span> <span class="kd">final</span> <span class="kd">static</span> <span class="n">IntWritable</span> <span class="n">one</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="kd">private</span> <span class="n">Text</span> <span class="n">word</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="p">();</span>

    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">map</span><span class="p">(</span><span class="n">Object</span> <span class="n">key</span><span class="p">,</span> <span class="n">Text</span> <span class="n">value</span><span class="p">,</span> <span class="n">Context</span> <span class="n">context</span>
                    <span class="p">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="p">,</span> <span class="n">InterruptedException</span> <span class="p">{</span>
      <span class="n">StringTokenizer</span> <span class="n">itr</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringTokenizer</span><span class="p">(</span><span class="n">value</span><span class="p">.</span><span class="na">toString</span><span class="p">());</span>
      <span class="k">while</span> <span class="p">(</span><span class="n">itr</span><span class="p">.</span><span class="na">hasMoreTokens</span><span class="p">())</span> <span class="p">{</span>
        <span class="n">word</span><span class="p">.</span><span class="na">set</span><span class="p">(</span><span class="n">itr</span><span class="p">.</span><span class="na">nextToken</span><span class="p">());</span>
        <span class="n">context</span><span class="p">.</span><span class="na">write</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">one</span><span class="p">);</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">IntSumReducer</span>
       <span class="kd">extends</span> <span class="n">Reducer</span><span class="o">&lt;</span><span class="n">Text</span><span class="p">,</span><span class="n">IntWritable</span><span class="p">,</span><span class="n">Text</span><span class="p">,</span><span class="n">IntWritable</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="kd">private</span> <span class="n">IntWritable</span> <span class="n">result</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="p">();</span>

    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">reduce</span><span class="p">(</span><span class="n">Text</span> <span class="n">key</span><span class="p">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">IntWritable</span><span class="o">&gt;</span> <span class="n">values</span><span class="p">,</span>
                       <span class="n">Context</span> <span class="n">context</span>
                       <span class="p">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="p">,</span> <span class="n">InterruptedException</span> <span class="p">{</span>
      <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
      <span class="k">for</span> <span class="p">(</span><span class="n">IntWritable</span> <span class="n">val</span> <span class="p">:</span> <span class="n">values</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span><span class="p">.</span><span class="na">get</span><span class="p">();</span>
      <span class="p">}</span>
      <span class="n">result</span><span class="p">.</span><span class="na">set</span><span class="p">(</span><span class="n">sum</span><span class="p">);</span>
      <span class="n">context</span><span class="p">.</span><span class="na">write</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">result</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="p">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="p">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="p">{</span>
    <span class="n">Configuration</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Configuration</span><span class="p">();</span>
    <span class="n">Job</span> <span class="n">job</span> <span class="o">=</span> <span class="n">Job</span><span class="p">.</span><span class="na">getInstance</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="s">"word count"</span><span class="p">);</span>
    <span class="n">job</span><span class="p">.</span><span class="na">setJarByClass</span><span class="p">(</span><span class="n">WordCount</span><span class="p">.</span><span class="na">class</span><span class="p">);</span>
    <span class="n">job</span><span class="p">.</span><span class="na">setMapperClass</span><span class="p">(</span><span class="n">TokenizerMapper</span><span class="p">.</span><span class="na">class</span><span class="p">);</span>
    <span class="n">job</span><span class="p">.</span><span class="na">setCombinerClass</span><span class="p">(</span><span class="n">IntSumReducer</span><span class="p">.</span><span class="na">class</span><span class="p">);</span>
    <span class="n">job</span><span class="p">.</span><span class="na">setReducerClass</span><span class="p">(</span><span class="n">IntSumReducer</span><span class="p">.</span><span class="na">class</span><span class="p">);</span>
    <span class="n">job</span><span class="p">.</span><span class="na">setOutputKeyClass</span><span class="p">(</span><span class="n">Text</span><span class="p">.</span><span class="na">class</span><span class="p">);</span>
    <span class="n">job</span><span class="p">.</span><span class="na">setOutputValueClass</span><span class="p">(</span><span class="n">IntWritable</span><span class="p">.</span><span class="na">class</span><span class="p">);</span>
    <span class="n">FileInputFormat</span><span class="p">.</span><span class="na">addInputPath</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="k">new</span> <span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span><span class="p">));</span>
    <span class="n">FileOutputFormat</span><span class="p">.</span><span class="na">setOutputPath</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="k">new</span> <span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="o">[</span><span class="mi">1</span><span class="o">]</span><span class="p">));</span>
    <span class="n">System</span><span class="p">.</span><span class="na">exit</span><span class="p">(</span><span class="n">job</span><span class="p">.</span><span class="na">waitForCompletion</span><span class="p">(</span><span class="kc">true</span><span class="p">)</span> <span class="o">?</span> <span class="mi">0</span> <span class="p">:</span> <span class="mi">1</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p data-pid="KOr4-4HF">编译并打包成jar</p><div class="highlight"><pre><code class="language-bash"><span></span>hadoop com.sun.tools.javac.Main WordCount.java
jar cf wc.jar WordCount*.class
</code></pre></div><p data-pid="22Uc8lTz">新建两个文本文件</p><div class="highlight"><pre><code class="language-bash"><span></span>vim <span class="nv">file01</span>
<span class="o">===========================</span>
Hello World Bye World

vim <span class="nv">file02</span>
<span class="o">===========================</span>
Hello Hadoop Goodbye Hadoop
</code></pre></div><p data-pid="ImCDTNQZ">在HDFS文件系统中新建一个文件夹存放输入，HDFS文件系统的命令用法可以参考官方文档：<a href="http://link.zhihu.com/?target=http%3A//hadoop.apache.org/docs/r3.3.1/hadoop-project-dist/hadoop-common/FileSystemShell.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">File System Shell</a>。注意这里我们不创建输出文件夹，可能是因为程序逻辑的问题，在output文件夹已存在的时候反而会报错。</p><div class="highlight"><pre><code class="language-bash"><span></span>hadoop fs -mkdir -p /user/input
</code></pre></div><p data-pid="DUXeA_MI">接下来将文本文档从本地文件系统拷贝到HDFS中</p><div class="highlight"><pre><code class="language-bash"><span></span>hadoop fs -put file0* /user/input/
</code></pre></div><p data-pid="OBmLy8md">使用以下命令运行该任务</p><div class="highlight"><pre><code class="language-bash"><span></span>hadoop jar wc.jar WordCount /user/input /user/output
---------------------------------------------------------------------------------------------------
...
<span class="m">2021</span>-06-27 <span class="m">19</span>:54:09,820 INFO mapreduce.Job: Running job: job_1624794834749_0001
<span class="m">2021</span>-06-27 <span class="m">19</span>:54:22,147 INFO mapreduce.Job: Job job_1624794834749_0001 running in uber mode : <span class="nb">false</span>
<span class="m">2021</span>-06-27 <span class="m">19</span>:54:22,148 INFO mapreduce.Job:  map <span class="m">0</span>% reduce <span class="m">0</span>%
<span class="m">2021</span>-06-27 <span class="m">19</span>:54:33,319 INFO mapreduce.Job:  map <span class="m">100</span>% reduce <span class="m">0</span>%
<span class="m">2021</span>-06-27 <span class="m">19</span>:54:41,392 INFO mapreduce.Job:  map <span class="m">100</span>% reduce <span class="m">100</span>%
<span class="m">2021</span>-06-27 <span class="m">19</span>:54:41,406 INFO mapreduce.Job: Job job_1624794834749_0001 completed successfully
...
</code></pre></div><p data-pid="n4OhykNo">然后使用以下命令查看运行结果</p><div class="highlight"><pre><code class="language-bash"><span></span>hadoop fs -cat /user/output/part-r-00000
----------------------------------------
Bye	<span class="m">1</span>
Goodbye	<span class="m">1</span>
Hadoop	<span class="m">2</span>
Hello	<span class="m">2</span>
World	<span class="m">2</span>
</code></pre></div><p data-pid="AeaBFyA4">以上是官网提供的例程，还需要进一步研读Java的用法。对于这种小规模的Toy dataset，MapReduce在效率上实际是不占优势的。以上程序运行得非常慢，看时间戳可以发现，不算前后其他过程，只是作业的执行，就使用了21秒。更多的例子请参考官方教程。</p>