<p data-pid="WnoZYk23">将来游戏中必然融入AI大模型技术，以生成更加逼真的NPC对话、行为甚至是高分辨率画面。参考目前AI大模型链式调用的工作流程，引入大量多版本模型组件，可能对存储空间提出更高的需求。直观地看，GPT-4的参数量为1.8万亿，假如使用8比特量化，恰好占用1.8TB存储。</p><p data-pid="i-5z4cXU">最简单的对话类游戏，正在逐渐融入LLM（大语言模型）。Inworld<sup data-text="Inworld" data-url="https://studio.inworld.ai/workspaces/default-g23qmylkc8prbmd6einsrg/characters" data-draft-node="inline" data-draft-type="reference" data-numero="1">[1]</sup>提供了在线的对话NPC生成服务，用户只需提供一段提示词作为人物背景，然后用滑块控制人物性格（想象一下可调的MBTI），就能得到一个可以直接对话的机器人。最近我也在尝试对开源LLM微调，生成通用的海龟汤<sup data-text="情境猜谜" data-url="https://zh.wikipedia.org/zh-cn/%E6%83%85%E5%A2%83%E7%8C%9C%E8%AC%8E" data-draft-node="inline" data-draft-type="reference" data-numero="2">[2]</sup>机器人，给定汤面和汤底，与用户进行无限轮次的交互。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/50/v2-0779397b5723d970dafa7af47435ae59_720w.jpg?source=c8b7c179" data-caption="" data-size="normal" data-rawwidth="3470" data-rawheight="1632" data-original-token="v2-26e4f79cd342874f06aa51361d1f4aec" data-default-watermark-src="https://pica.zhimg.com/50/v2-224ca94b3ddae1c5a48b2abdb4f1972d_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb" width="3470" data-original="https://pic1.zhimg.com/v2-0779397b5723d970dafa7af47435ae59_r.jpg?source=c8b7c179"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='3470'%20height='1632'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="3470" data-rawheight="1632" data-original-token="v2-26e4f79cd342874f06aa51361d1f4aec" data-default-watermark-src="https://pica.zhimg.com/50/v2-224ca94b3ddae1c5a48b2abdb4f1972d_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb lazy" width="3470" data-original="https://pic1.zhimg.com/v2-0779397b5723d970dafa7af47435ae59_r.jpg?source=c8b7c179" data-actualsrc="https://picx.zhimg.com/50/v2-0779397b5723d970dafa7af47435ae59_720w.jpg?source=c8b7c179"></figure><p data-pid="zSmbqPiI">LLM还将被用于控制角色的行为。尽管强化学习模型参数大多不超过5千万<sup data-text="Parameter Scaling Comes for RL, Maybe" data-url="https://www.lesswrong.com/posts/4xGAmZ9GTGAkszHoH/parameter-scaling-comes-for-rl-maybe" data-draft-node="inline" data-draft-type="reference" data-numero="3">[3]</sup>，近来大量学者开始关注将LLM用于决策，打造更像人类的通用机器人<sup data-text="通用机器人前沿进展与思考" data-url="https://zhuanlan.zhihu.com/p/572161818" data-draft-node="inline" data-draft-type="reference" data-numero="4">[4]</sup>。LLM在这里扮演神经中枢的角色，统筹着感受器（传感器）与效应器（电机等）。</p><p data-pid="4CIH2JK7">实际部署前，强化学习模型通常会在仿真环境内模拟训练，学习面对不同环境状态最优的策略或者值函数。而游戏，决策复杂且易于仿真控制，成为强化学习中最热门的领域之一。</p><p data-pid="WTgTzOOE">今年4月，斯坦福学者打造「AI小镇」<sup data-text="Generative agents: Interactive simulacra of human behavior" data-url="https://arxiv.org/pdf/2304.03442.pdf" data-draft-node="inline" data-draft-type="reference" data-numero="5">[5]</sup>，利用生成式模型模拟具有可信人类行为的智能体，玩家可以通过与角色对话、改变环境状态或扮演某个角色的方式影响游戏进程。想象一下，未来游戏中的角色是自然生成的，他们自顾自生活着，甚至会形成自己的社会，就像现在我们用随机种子生成地图一样简单。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/50/v2-49f291752d3200f549d99d6a2280b036_720w.jpg?source=c8b7c179" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="680" data-original-token="v2-ef67c60a5719184f9f023e02dbca9982" data-default-watermark-src="https://picx.zhimg.com/50/v2-814d6705cc86a1cb7803666f021bea8b_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://picx.zhimg.com/v2-49f291752d3200f549d99d6a2280b036_r.jpg?source=c8b7c179"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1080'%20height='680'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="680" data-original-token="v2-ef67c60a5719184f9f023e02dbca9982" data-default-watermark-src="https://picx.zhimg.com/50/v2-814d6705cc86a1cb7803666f021bea8b_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://picx.zhimg.com/v2-49f291752d3200f549d99d6a2280b036_r.jpg?source=c8b7c179" data-actualsrc="https://picx.zhimg.com/50/v2-49f291752d3200f549d99d6a2280b036_720w.jpg?source=c8b7c179"></figure><p data-pid="WRm4zLjf">以Midjourney和StableDiffusion为代表的文生图模型，或将接管游戏中某些画面甚至是3D模型的生成。尽管目前消费级显卡的推理速度远不能满足实时需求（RTX 3060生成512x712图像需6~8秒），我们可以看出AI大模型的未来趋势。文生图过程中，首先使用基础模型“打草稿”，配合ControlNet控笔，然后使用相对轻量的LoRA模型精修细节。为了应对不同的题材和画风，我们就需要大量个性化的基础模型和LoRA模型<sup data-text="civitai" data-url="https://civitai.com/" data-draft-node="inline" data-draft-type="reference" data-numero="6">[6]</sup>，这将导致存储需求暴增。</p><p data-pid="VLs5VK0r">以上讨论中，我使用“可能”而不是“一定”来形容存储需求，是因为比起硬盘存储，内存、显存和算力更容易成为AI大模型在游戏中应用的瓶颈，而考虑到后摩尔时代芯片性能接近饱和，在本地运行AI大模型并不是最合理的选择。</p><p data-pid="8iys5EQu">也许大多数游戏厂商会将AI服务部署在云侧，但并不消除将来出现流式大模型或插件式大模型的可能。我在20年关注淘宝商品三维重建方面的工作，他们其中一条技术路线就是使用后来爆火的NeRF模型取代点云+贴图或伪3D的传统方法。我当时的想法是，能否实现一个嵌套模型，像视频一样增量地传输参数，对3D画面进行逐渐清晰的渲染。</p><p data-pid="wo9Mkh9b">高分辨率的模型贴图和视频是目前大型游戏的存储主体，除VR/AR等特殊设备对分辨率有更高的要求外，其实增加细节已经对游戏体验帮助不大，4K以上的显示器和4K的差距并不明显。而且模型渲染同样可以被卸载到云服务器上，如果网络延迟足够低，云侧资源充足，反而会削减端侧的存储需求。</p><p data-pid="pG6l9OXO">除细节以外，场景的规模也会影响游戏大小。如果AIGC能够把设计成本削减下来，我们有望看到极其庞大的游戏。那时我们可以轻松地在城市级复杂场景之间穿梭，画面内没有任何东西不可交互，一切固定的模式都将被打破，只剩下简洁的物理引擎运转着。同样，我并不认为这一切必然带来存储的激增，贴图和AI模型仍可以MOD或流媒体的方式被逐一渲染和加载。</p>