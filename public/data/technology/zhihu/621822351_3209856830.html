<p data-pid="owguT20l">文生图开源模型Stable Diffusion只有十亿参数，可以在绝大多数消费级显卡上部署，运行效果与不开源的Midjourney难分伯仲；LLM的代表模型GPT-4拥有1.8万亿参数，普通开发者基本没有可能本地部署，而开源的轻量化LLM与GPT-4的能力相差极大，是腐草之荧光与当空之皓月。</p><p data-pid="HN0TdUOz">也就是说，文生图模型技术壁垒较低、成熟度高，探索新的模型结构意义相对不大。而LLM仍然存在大量研究难点，谁在这个上面有突破，谁就青史留名。国内外涌现了大量此类的公司和学者，开源只不过是在恰当的时机扩大影响力的手段罢了。</p><p data-pid="dEYeO6rH">文生图模型生态更像是一个稳定的国家，Stable Diffusion经历1.X到2.X的版本更新，推出全面优化后的SDXL系列，是子承父业慢慢改进。<a href="https://link.zhihu.com/?target=https%3A//civitai.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">civitai</a>里不同风格的个性化模型好似不同的民族，但归根到底有相同的渊源。而LLM更像春秋战国，群雄并起、各自为战，大家心里都有一个远大的社会理想，无论是为了个人的影响力还是为了全社会的进步。</p><p data-pid="vt2vStHr">如果有一天，我们在8GB的显卡上就可以轻松运行甚至微调GPT-4这种能力的开源模型，LLM的战局也会稳定下来，然后优胜劣汰，最后只剩下几个耳熟能详的，就像如今的PyTorch与TensorFlow一样。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/50/v2-8f4534e72f77636b7c19a7f0f7c83f7c_720w.jpg?source=c8b7c179" data-size="normal" data-rawwidth="2112" data-rawheight="1596" data-original-token="v2-7df8e898ad81c9fa39f8faa8af3707c3" data-default-watermark-src="https://picx.zhimg.com/50/v2-57ddc5bd82e42dadea38da6c5b002a3d_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb" width="2112" data-original="https://pic1.zhimg.com/v2-8f4534e72f77636b7c19a7f0f7c83f7c_r.jpg?source=c8b7c179"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='2112'%20height='1596'&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2112" data-rawheight="1596" data-original-token="v2-7df8e898ad81c9fa39f8faa8af3707c3" data-default-watermark-src="https://picx.zhimg.com/50/v2-57ddc5bd82e42dadea38da6c5b002a3d_720w.jpg?source=c8b7c179" class="origin_image zh-lightbox-thumb lazy" width="2112" data-original="https://pic1.zhimg.com/v2-8f4534e72f77636b7c19a7f0f7c83f7c_r.jpg?source=c8b7c179" data-actualsrc="https://picx.zhimg.com/50/v2-8f4534e72f77636b7c19a7f0f7c83f7c_720w.jpg?source=c8b7c179"><figcaption>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</figcaption></figure><p></p>