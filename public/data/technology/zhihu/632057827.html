<p data-pid="BH2URZrV">我长期从事端侧机器学习系统课程助教，指导PRP相关研究项目，从学生那里积累和学习了诸多端侧软硬件方面的经验。本文作为Nano上的经验帖，将会长期更新，有疑问的小伙伴可以来评论区留言，也欢迎有其他经验的同学向我投稿。之前也写过一些关于树莓派的经验帖，欢迎关注！</p><ul><li data-pid="Oc7L-x28"><a href="https://zhuanlan.zhihu.com/p/374384494" class="internal" target="_blank">清川：树莓派无外设开发一：注入灵魂、建立通信</a></li><li data-pid="zbSHpM63"><a href="https://zhuanlan.zhihu.com/p/374415447" class="internal" target="_blank">清川：树莓派无外设开发二：root用户ssh免密码登录</a></li><li data-pid="zluRXOcC"><a href="https://zhuanlan.zhihu.com/p/374435571" class="internal" target="_blank">清川：树莓派无外设开发三：自动连接无线网</a></li></ul><hr/><blockquote data-pid="9Kho98fp">本文基于创乐博的Jetson Nano B01国产板（<a href="https://link.zhihu.com/?target=https%3A//item.m.jd.com/product/52914065067.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">京东商品详情页</a>），上位机使用一台Win11系统的PC。国产板不能直接使用英伟达官方系统镜像，需要格外注意。——2023年5月</blockquote><h2>1 型号简介</h2><p data-pid="_S3rVZ8X">英伟达的Jetson系列专注于边缘端AI平台，在2017年发布Pascal架构的TX2子系列，然后在2018~2020年发布Volta架构的Xavier子系列，在2019年发布Maxwell架构的Nano，在2022年发布Ampere架构的Orin子系列。其中Xavier子系列下又包含了AGX Xavier和Xavier NX。2022年的Orin大幅提升性能，但提供了与Xavier的AGX、NX以及Nano的核心板尺寸、引脚分别兼容的AGX Orin、Orin NX和Orin Nano。尺寸横向兼容的好处是，已经作为系统模块部署的开发板可以直接更新换代。当然，除了开发板以外，Jetson也提供面向生产环境的设备，比如TXi和Orin/Xavier的industrial系列。</p><p data-pid="9eQOhfwK">我们手里的Jetson开发板一般包括上下两层，上面的叫核心板，下面的叫载板（或母板、底板）。核心板上嵌入了封装好CPU、GPU、内存与视频编解码器等器件的Tegra架构SoC，以及一块可以看做是ROM的eMMC闪存。载板上则扩展了更多的外设接口，比如HDMI口、网口、USB口等。除了两款Nano和AGX Orin提供了官方载板以外，其他型号都只提供核心板。于是有很多下游厂商生产自己的载板，有些载板可能包含了扩展的接口、WiFi和存储器，所以需要额外的软件驱动。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-2204590c6463ea23123a2ac2b793fb48_1440w.jpg" data-size="normal" data-rawwidth="2000" data-rawheight="1000" class="origin_image zh-lightbox-thumb" width="2000" data-original="https://pic3.zhimg.com/v2-2204590c6463ea23123a2ac2b793fb48_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2000&#39; height=&#39;1000&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2000" data-rawheight="1000" class="origin_image zh-lightbox-thumb lazy" width="2000" data-original="https://pic3.zhimg.com/v2-2204590c6463ea23123a2ac2b793fb48_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-2204590c6463ea23123a2ac2b793fb48_1440w.jpg" data-original-token="v2-ac4235da4af04023e3a331373259a499"/><figcaption>Jetson系列的算力和售价对比图，仅供参考（1TOPS为每秒10^12次操作）</figcaption></figure><p data-pid="mX-LnFAE">Jetson的Nano、TX2/NX、AGX分别定位入门级、主流级和自主机器市场（这里的自主机器我理解的就包括自动驾驶和机器人），本文讨论的Nano是其中尺寸最小、性能最弱、价格最低的型号，具体性能对比请参考<a href="https://link.zhihu.com/?target=https%3A//developer.nvidia.com/embedded/jetson-modules%23tech_specs" class=" wrap external" target="_blank" rel="nofollow noreferrer">官网</a>。注意，英伟达在2020年发布了新版的Nano B01，而之前的A02已经停产了。B01的官方载板布局有所改进，主要是摄像头接口增加到2个，控制用的引脚位置发生了挪动。本文基于B01，国产的载板和官方载板布局基本一致。</p><p data-pid="Wq_4XXtf">下表给出了国产套件的一些规格，其中无线网卡是英伟达官方没有的。另外我还配置了一个IMX219摄像头。</p><table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><td>GPU</td><td>128-core Maxwell GPU, 512 GFLOPS (FP16), Maximum Operating Frequency: 921 MHz</td></tr><tr><td>CPU</td><td>Quad-Core ARM® Cortex® -A57 MPCore, 2 MB L2, Maximum Operating Frequency: 1.43 GHz</td></tr><tr><td>内存</td><td>4 GB 64-bit LPDDR4 @ 1600MHz | 25.6 GB/s</td></tr><tr><td>核心板闪存</td><td>16 GB eMMC 5.1 Flash Storage, Bus Width: 8-bit, Maximum Bus Frequency: 200 MHz (HS400)</td></tr><tr><td>摄像头总线</td><td>12 lanes MIPI CSI-2 | 1.5 Gbps per lane</td></tr><tr><td>输入电压电流</td><td>5V, 3A</td></tr><tr><td>尺寸</td><td>100mm x 80mm x 29mm</td></tr><tr><td>网络</td><td>千兆以太网, M.2KeyE (无线网卡)</td></tr><tr><td>USB</td><td>4xUSB3.0, 1xUSB2.0 Micro-B</td></tr><tr><td>其他接口</td><td>GPIO, 12C, 125, SPI, UART</td></tr></tbody></table><h2>2 硬件准备</h2><p data-pid="5YoAq6RC">除Nano开发板以外，还需要这些设备：</p><ul><li data-pid="zJq7Dyeq"><b>一个USB无线网卡 </b>or <b>网线</b></li><li data-pid="LQc2Xzap"><b>一根Micro-USB数据线</b></li><li data-pid="YP12DWzW"><b>一根USB-DC接口的连接线、一个5V-3A的电源适配器</b></li><li data-pid="PL9ha7by"><b>一张32GB及以上的TF卡、读卡器</b></li><li data-pid="V2T4iwez"><b>一套USB接口的鼠标、键盘</b></li><li data-pid="IsqAssPN"><b>一根HDMI视频线</b></li><li data-pid="1Lhx9_ZM"><b>一根两端母头的杜邦线</b></li></ul><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-4f5294eec24430bd51308a5429521b58_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="720" data-rawheight="323" class="origin_image zh-lightbox-thumb" width="720" data-original="https://pic1.zhimg.com/v2-4f5294eec24430bd51308a5429521b58_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;323&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="720" data-rawheight="323" class="origin_image zh-lightbox-thumb lazy" width="720" data-original="https://pic1.zhimg.com/v2-4f5294eec24430bd51308a5429521b58_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4f5294eec24430bd51308a5429521b58_1440w.jpg" data-original-token="v2-a403cd05c958f9bfd815cfe10d7841ce"/></figure><h3><b>关于网络</b></h3><p data-pid="z-toRfzz">店铺提供了M.2KeyE无线网卡，长得很像无线鼠标接收头。但实测这种微型网卡容易收到干扰，尤其是离的很近的USB口插有其他连接线时。我<b>时常在开机一段时间后遭遇网络中断，系统假联网</b>。看着是有IP地址，但已经扫描不出附近的网络了，这个时候就需要更换USB口试一下。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-b67fc809657a5797ebdfcc5992bc84da_1440w.jpg" data-size="normal" data-rawwidth="3772" data-rawheight="1280" class="origin_image zh-lightbox-thumb" width="3772" data-original="https://pic3.zhimg.com/v2-b67fc809657a5797ebdfcc5992bc84da_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;3772&#39; height=&#39;1280&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="3772" data-rawheight="1280" class="origin_image zh-lightbox-thumb lazy" width="3772" data-original="https://pic3.zhimg.com/v2-b67fc809657a5797ebdfcc5992bc84da_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-b67fc809657a5797ebdfcc5992bc84da_1440w.jpg" data-original-token="v2-a54f607eb904627b14338192a739c823"/><figcaption>有IP地址却ping不通网关的假联网现象</figcaption></figure><p data-pid="8oNXmnMs">如果有条件，还是建议购买带天线的高级网卡套件。注意，店铺中不带天线的Nano是没有网卡芯片插槽的。另外如果没有无线网卡，也可以找一台可控的路由器，用网线将Nano（J43）连接到路由器的LAN口上网。</p><h3>关于数据线</h3><p data-pid="jsR65NIU">Micro-USB接口长得像圆角矩形，而古早时期的Mini-USB接口长得像两个摞在一起的梯形，不要混淆。Micro-USB口（J28）可以供电也可以传输数据，通过载板上的跳线帽（短接片，J48）控制。选用DC接口（J25）供电时，将J48用跳线帽短接，选用Micro USB供电时，需要拔掉跳线帽。</p><h3>关于电源</h3><p data-pid="X0WkG7Sd">大一点的手机充电器基本都支持5V3A，比如快充是向下兼容的，有多档功率，接入时会协商充电协议，只要输出有5V3A的选项基本就不会烧掉Nano。不建议使用电脑的USB口供电，电流可能不够大，导致系统因为输入功率不足而进行节流。顺便提一下，Jetson的开发包Jetpack 4.5~4.6中有个固有bug，<b>系统会时不时提醒：<span class="nolink">System throttled due to Over-current</span></b>。这有可能是电源电压不足导致的，参考论坛的<a href="https://link.zhihu.com/?target=https%3A//forums.developer.nvidia.com/t/system-throttled-due-to-over-current/158055" class=" wrap external" target="_blank" rel="nofollow noreferrer">帖子</a>，最好不要使用太长的电源线，如果有条件可以把电源电压提高一点点，比如5.2V左右。</p><p data-pid="6J_aAFWZ">上面已经提到，Nano有两个现成的供电口（假设你不需要用引脚跳线的方式供电），一个是DC接口，一个是Micro USB接口，使用跳线帽进行选路。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-54882e8fed6ebadd7770b782e947505f_1440w.jpg" data-size="normal" data-rawwidth="2208" data-rawheight="1280" class="origin_image zh-lightbox-thumb" width="2208" data-original="https://picx.zhimg.com/v2-54882e8fed6ebadd7770b782e947505f_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2208&#39; height=&#39;1280&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="2208" data-rawheight="1280" class="origin_image zh-lightbox-thumb lazy" width="2208" data-original="https://picx.zhimg.com/v2-54882e8fed6ebadd7770b782e947505f_r.jpg" data-actualsrc="https://picx.zhimg.com/v2-54882e8fed6ebadd7770b782e947505f_1440w.jpg" data-original-token="v2-6992658317c64f5e683a1cf473469c22"/><figcaption>背面视角</figcaption></figure><h3>关于外壳</h3><p data-pid="MzofViJL">外壳可以避免一些特殊情况下的损坏，比如桌面有水，运行中的板子放在上面可能短路，又比如不小心在板子上面放了重物压坏了芯片，这些都是血淋淋的例子。</p><p data-pid="yWmtw9Ci">如上图安装套件中的亚克力外壳框架，使用塑料垫片将载板底部垫高，然后外部使用铜柱支撑。注意四角的螺丝不要上太紧，亚克力板很脆容易开裂。框架的安装建议在固件烧写之后，因为刷固件的时候需要用到控制引脚（Button Head），而正面SD卡侧的挡板会遮住这些引脚。</p><h2>3 前期基础环境配置</h2><h3>3.1 刷写固件</h3><p data-pid="SEtF8pbR">这里的固件是指存储在核心板eMMC中的BootLoader，负责从系统盘加载Linux内核到内存中。一般来说只需要刷写一遍，如果实验过程中系统崩溃，只需要重新烧写TF卡中的系统镜像。</p><p data-pid="iS4DwVg0">首先安装VMWare WorkStations Pro，在网上找个注册码破解一下。然后将资料盘中的虚拟机镜像解压到PC的某个文件夹下。这个店家的资料盘中的镜像大多是分卷压缩的，即有很多编号连续的压缩包，只需要解压part01。我使用的是7zip解压软件，好用而且没有广告，是业界良心。之后在VMWare中打开这个文件夹下的vmx文件，加载并启动虚拟机。Windows11+WorkStations15加载虚拟机的时候会报错</p><div class="highlight"><pre><code class="language-text">(vcpu-1) Exception 0xc0000005 (access violation) has occurred.</code></pre></div><p data-pid="Lq9KPkzu">参考<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/weixin_42723246/article/details/124594498" class=" wrap external" target="_blank" rel="nofollow noreferrer">终极解决方案</a>，只需要把虚拟机的CPU和线程数量都修改为1，即可成功加载。</p><p data-pid="QrlTX0v_">使用杜邦线短接控制引脚的9、10引脚，即从摄像头接口一侧向左数的第3、4引脚，请参考Nano的<a href="https://link.zhihu.com/?target=https%3A//developer.download.nvidia.cn/assets/embedded/secure/jetson/Nano/docs/NV_Jetson_Nano_Developer_Kit_User_Guide.pdf%3FbOlDsI36opCbSB2trRGIxgVTbNnm6mXMNe_Rv8wxm-LRLaN_0X10xBveICpQnCcoIAM3NUz15vepoyvcZzRIPZeYu9oa5cRuAiU9I0ryLXEDJS9Gn68a_EX8v0TJ6jimhqlTmWHOgMMMK1KGORXm7WXLtGNqkOHLWSWdeZXSevINgAnSa-BawDauTct0crZDBVU%3D%26t%3DeyJscyI6ImdzZW8iLCJsc2QiOiJodHRwczovL3d3dy5nb29nbGUuY29tLyJ9" class=" wrap external" target="_blank" rel="nofollow noreferrer">官方用户手册</a>。然后使用Micro-USB连接线连接Nano和上位机，之后DC电源上电。可以看到电源指示灯亮，虚拟机弹窗提示检测到新的USB设备，选择连接到虚拟机。如果电源指示灯不亮需要检查跳线帽是否正确，如果实在没有这个弹窗，可以参考下面故事中的方法重置系统。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-df23fdd701b993c68b2d32077c6c6a14_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="643" data-rawheight="283" class="origin_image zh-lightbox-thumb" width="643" data-original="https://pic1.zhimg.com/v2-df23fdd701b993c68b2d32077c6c6a14_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;643&#39; height=&#39;283&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="643" data-rawheight="283" class="origin_image zh-lightbox-thumb lazy" width="643" data-original="https://pic1.zhimg.com/v2-df23fdd701b993c68b2d32077c6c6a14_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-df23fdd701b993c68b2d32077c6c6a14_1440w.jpg" data-original-token="v2-ac24eec301a82e663c30447113cf355f"/></figure><p data-pid="UcxUfejU">进入/home/linux_for_Tegra文件夹，如果没有这个文件夹，就从资料盘中拖进来。在这个文件夹下运行终端，输入以下命令</p><div class="highlight"><pre><code class="language-bash">sudo ./flash.sh -r jetson-nano-devkit-emmc mmcblk0p1</code></pre></div><p data-pid="DEEHHo14">密码默认是<code>nvidia</code>。之后会出现大量回显，等待一段时间，直到最后看到</p><div class="highlight"><pre><code class="language-text">The target has been flashed successfully. ***
Make the target filesystem available to the device and reset the board to boot from external sdcard.</code></pre></div><p data-pid="WwVMQ3Gi">就说明固件刷写成功。关闭电源，然后拔掉短接的杜邦线，接上显示器，然后重新上电。注意操作的顺序，我们始终先接显示器，后上电。因为开机时会检测是否有视频输出，如果没有，系统会自动进入到headless模式。这时我们没有插TF卡，系统仍然能开机，但是会停留在命令行模式，并提示</p><div class="highlight"><pre><code class="language-text">[1.167700] tegradc tegradc.1: dpd enable lookup fail:-19
[1.324122] imx219 7-0010: imx219 board setup: error during i2c read probe (-121)
[1.324189] imx219 7-0010: board setup failed
[1.348016] imx219 8-0010: imx219 board setup: error during i2c read probe (-121)
[1.348078] imx219 8-0010: board setup failed
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
bash-4.4#</code></pre></div><p data-pid="GNaxLVEW">这个dpd不知道是啥，可能是低功耗开关没有打开。然后扫描到摄像头接口的时候也失败了，因为没有接。以上都是可以忽略的正常报错。后面bash的报错说明没有导入系统成功，因为我们没有插入TF卡。这时的bash是eMMC中的BootLoader提供的，我们可以进行简单的交互。</p><p data-pid="AGr3r8Kg"><b>有个学生告诉我他的板子不插TF卡也能开机</b></p><p data-pid="kSQieGPo">我开始很惊讶，后来意识到，可能上一个使用设备的人把整个系统刷到板上的eMMC里了，并且配置了BootLoader从eMMC中加载系统。我不知道这是怎么做到的，但我知道如何恢复。根据Nano的<a href="https://link.zhihu.com/?target=https%3A//developer.download.nvidia.cn/assets/embedded/secure/jetson/Nano/docs/NV_Jetson_Nano_Developer_Kit_User_Guide.pdf%3FbOlDsI36opCbSB2trRGIxgVTbNnm6mXMNe_Rv8wxm-LRLaN_0X10xBveICpQnCcoIAM3NUz15vepoyvcZzRIPZeYu9oa5cRuAiU9I0ryLXEDJS9Gn68a_EX8v0TJ6jimhqlTmWHOgMMMK1KGORXm7WXLtGNqkOHLWSWdeZXSevINgAnSa-BawDauTct0crZDBVU%3D%26t%3DeyJscyI6ImdzZW8iLCJsc2QiOiJodHRwczovL3d3dy5nb29nbGUuY29tLyJ9" class=" wrap external" target="_blank" rel="nofollow noreferrer">官方用户手册</a>，将J50控制引脚中的7和8短接（也就是将SYS RST引脚接地），可以在系统运行时重置系统。于是我在开机的状态下，使用杜邦线短接这两个引脚，之后重启就恢复到出厂设置了，接下来按照上述过程刷写固件即可。</p><h3>3.2 烧写系统</h3><p data-pid="0OcREREA">使用读卡器将TF卡接入上位机。上位机安装烧入工具balenaEtcher。将店铺提供的系统镜像解压到某个文件夹下，会得到6.17GB的镜像压缩包，这时候可以解压得到15GB左右的img文件，也可以不解压，因为烧入工具支持zip格式。这里要注意不要在资料U盘本地解压，因为磁盘空间不足会提前终止，然后得到一个损坏的镜像文件。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-52452bb0c301693f68368c9f5a98ebbd_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="2133" data-rawheight="1280" class="origin_image zh-lightbox-thumb" width="2133" data-original="https://pic4.zhimg.com/v2-52452bb0c301693f68368c9f5a98ebbd_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;2133&#39; height=&#39;1280&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="2133" data-rawheight="1280" class="origin_image zh-lightbox-thumb lazy" width="2133" data-original="https://pic4.zhimg.com/v2-52452bb0c301693f68368c9f5a98ebbd_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-52452bb0c301693f68368c9f5a98ebbd_1440w.jpg" data-original-token="v2-f61f73cdf569754e73eff7b809eaa8e4"/></figure><p data-pid="l7TJdyKm">select target那里选中插入的TF卡，然后点击Flash，大约等待20分钟，系统就会烧录和验证成功。然后直接拔掉读卡器就可以了。</p><p data-pid="QJz3kZkb">这个店铺提供的国产镜像打包了Jetpack4.6.1和CUDA10.2，如果想要使用英伟达官方的镜像，我们不能直接从官网下载，而要在虚拟机中使用SDK Manager一步一步配置，然后刷写固件再烧入系统。这样做没太大必要，从官网的<a href="https://link.zhihu.com/?target=https%3A//developer.nvidia.com/embedded/jetpack-archive" class=" wrap external" target="_blank" rel="nofollow noreferrer">兼容性列表</a>中可以看到，Nano支持的Jetpack最高版本是4.6.3，而Jetpack4.6最高只支持CUDA10.2，而且CUDA10.2是非安培架构GPU上性能最好的版本，所以国产镜像并不算陈旧。</p><h3>3.3 分区扩容</h3><p data-pid="upaVwMPl">将TF卡插入到Nano中，然后上电，可以正常进入系统。如果完全黑屏说明供电或者固件有问题。如果卡在某个命令行界面说明BootLoader加载的时候遇到问题，大概率是系统镜像出错，这时候需要重新烧录系统。</p><p data-pid="WFBT4nX2">店铺提供的系统默认分区大小是16GB，而系统本身就有12GB左右，所以需要进行扩容。用df命令查看空间可以验证这件事。</p><div class="highlight"><pre><code class="language-bash">nvidia@nvidia-desktop:~$ df -lh
FileSystem  Size    Used    Avail   Use%    Mounted on
/dev/sda1    15G     12G     2.1G    86%    /
...</code></pre></div><p data-pid="7jg9ME7d">接下来使用Linux系统上常用的图形化磁盘工具GParted修改分区大小，我们只需要用apt命令安装即可。在安装之前，需要先使用update拉取资源索引列表。首先更新apt源为清华源来避免网络超时问题，修改源配置文件</p><div class="highlight"><pre><code class="language-bash">sudo gedit /etc/apt/sources.list</code></pre></div><p data-pid="G83xlK84">删除原有内容，粘贴以下内容</p><div class="highlight"><pre><code class="language-text"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse
deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse</code></pre></div><p data-pid="Ou0ayfM0">然后拉取索引列表</p><div class="highlight"><pre><code class="language-bash">sudo apt-get update</code></pre></div><p data-pid="iOIH6U3C">注意这里<b>在update之后一定不要直接upgrade</b>，它会默认将系统所有软件进行更新而且不可逆。经验上，它会更新显卡驱动导致版本不适配，从而在重启时提示找不到显卡，无法进入图形界面。接下来，安装GParted</p><div class="highlight"><pre><code class="language-bash">sudo apt-get install gparted</code></pre></div><p data-pid="oqW5-hpV">安装成功之后，启动</p><div class="highlight"><pre><code class="language-text">sudo gparted</code></pre></div><p data-pid="xgk6F6gm">在右上角切换到磁盘/dev/sda，可以看到有一半的空间处于未分配状态。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-50b9dd704c8cccb911f6c8ee0fef4572_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="564" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pic1.zhimg.com/v2-50b9dd704c8cccb911f6c8ee0fef4572_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1920&#39; height=&#39;564&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="564" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://pic1.zhimg.com/v2-50b9dd704c8cccb911f6c8ee0fef4572_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-50b9dd704c8cccb911f6c8ee0fef4572_1440w.jpg" data-original-token="v2-b99ea30c040f4bd0fb993b54d9b3a092"/></figure><p data-pid="r2nYYPdW">右键已分配空间的分区，选择Resize，拖动上面的游标将空间大小设置到最大。</p><figure data-size="normal"><noscript><img src="https://pica.zhimg.com/v2-171231c6f4ddbda5a82b2dcee82aaf02_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="587" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pica.zhimg.com/v2-171231c6f4ddbda5a82b2dcee82aaf02_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1920&#39; height=&#39;587&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="587" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://pica.zhimg.com/v2-171231c6f4ddbda5a82b2dcee82aaf02_r.jpg" data-actualsrc="https://pica.zhimg.com/v2-171231c6f4ddbda5a82b2dcee82aaf02_1440w.jpg" data-original-token="v2-8b0bbecf4e49a15f0bf47ba75204f028"/></figure><p data-pid="oKyidoVV">然后点击上面的绿色对钩，确认更改。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-b0b11cf8d0d20acf860e911337bb65e8_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="570" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pic3.zhimg.com/v2-b0b11cf8d0d20acf860e911337bb65e8_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1920&#39; height=&#39;570&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="570" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://pic3.zhimg.com/v2-b0b11cf8d0d20acf860e911337bb65e8_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-b0b11cf8d0d20acf860e911337bb65e8_1440w.jpg" data-original-token="v2-8bd62f872331871b537847c75c7a9e70"/></figure><p data-pid="a73mwG57">这时我们的主分区就扩展到整个TF卡大小了。</p><h3>3.4 风扇自启动</h3><p data-pid="jFK2RyiQ">系统高负荷运行时板子还是很烫的，所以设置风扇开机时自启动，前提是风扇已经安装。编辑自启动脚本</p><div class="highlight"><pre><code class="language-bash">sudo gedit /etc/rc.local</code></pre></div><p data-pid="PnK6qxyD">写入命令，控制风扇运转到最高功率的100/255。</p><div class="highlight"><pre><code class="language-bash"><span class="cp">#!/bin/bash
</span><span class="cp"></span>sudo sh -c <span class="s1">&#39;echo 100 &gt; /sys/devices/pwm-fan/target_pwm&#39;</span></code></pre></div><p data-pid="9l3q5aP4">然后需要赋予脚本执行权限，这一点非常重要</p><div class="highlight"><pre><code class="language-bash">sudo chmod <span class="m">755</span> /etc/rc.local</code></pre></div><h3>3.5 SSH远程登录</h3><p data-pid="wcCRhd5C">一方面，由于Nano的内存和显存是共用的，关闭图形界面可以节省1GB以上的显存，另一方面，由于命令行更利于对大规模集群进行批量控制，所以接下来配置Nano以支持SSH远程登录。由于Nano本身已经开启了SSH服务，只需要配置一下静态IP和免密登录。</p><p data-pid="N0wEpaNJ"><b>配置静态IP地址</b></p><p data-pid="v9vzBGd7">① 在桌面上打开“系统设置（System Settings）”-“网络（Network）”，点进当前连接的网络的详细设置（右边的小箭号）② 点“Settings...”-“IPv4 Settings”进入如下页面，把连接方式（Method）改为手动（Manual），在下方的地址栏填写IP地址、掩码、网关、DNS服务器等信息，点击“Save”。网关和DNS服务器一般填写路由器的内网IP即可。③ 重启网络服务或重启电脑使配置生效。这些操作是为了防止内网设备数量饱和时根据DHCP协议动态分配到的IP发生变化。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-3d347af49681fc24bd8850ff646a67a7_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1394" data-rawheight="519" class="origin_image zh-lightbox-thumb" width="1394" data-original="https://pic2.zhimg.com/v2-3d347af49681fc24bd8850ff646a67a7_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1394&#39; height=&#39;519&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1394" data-rawheight="519" class="origin_image zh-lightbox-thumb lazy" width="1394" data-original="https://pic2.zhimg.com/v2-3d347af49681fc24bd8850ff646a67a7_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-3d347af49681fc24bd8850ff646a67a7_1440w.jpg" data-original-token="v2-4fd8e9f68f7ccef46eba2af2b5a8168b"/></figure><p data-pid="-Yhp9FGi"><b>配置SSH免密登录</b></p><p data-pid="zErJNE5z">① 检查上位机的公钥文件是否存在：Windows检查 <code>C:\Users\用户名\.ssh\id_rsa.pub</code> ，Mac/Linux检查 <code>~/.ssh/id_rsa.pub</code> 。若此前配置过GitHub免密传输，很可能具备该文件。如果公钥文件不存在，则在终端输入命令 <code>ssh-keygen -t rsa</code> ，然后一直回车到底，默认会在以上路径生成公钥文件。<b>需要注意</b> 以 <code>.</code> 开头的文件是隐藏文件，windows需要在资源管理器查看菜单勾选隐藏文件选项，Mac/Linux使用 <code>ls -a</code> 。② 将公钥文件使用U盘拷贝至Nano上。创建~/.ssh文件夹，在该文件夹下创建authorized_keys文件，然后将公钥内容拷贝进去。如果U盘不方便，也可以直接在上位机使用如下命令开启http服务器，在Nano上使用浏览器访问上位机的IP地址进行下载。</p><div class="highlight"><pre><code class="language-bash">python3 -m http.server <span class="m">80</span> </code></pre></div><p data-pid="ErR5moKZ">但一定要注意安全问题，保证内网中没有窃听者。③ 使用如下命令重启SSH服务</p><div class="highlight"><pre><code class="language-bash">service ssh restart</code></pre></div><p data-pid="owpgei1m">然后在上位机就可以访问了。下面的例子中Nano的IP地址是192.168.1.109，用户名是nvidia。</p><ul><li data-pid="iaavlfgh">ssh nvidia@192.168.1.109</li></ul><h2>4 深度学习环境配置</h2><h3>4.1 安装PyTorch</h3><p data-pid="S-lZAiY9">首先我们可以清理一下多余的安装包。这一步不是必要的，但是可以释放一部分硬盘空间。</p><div class="highlight"><pre><code class="language-bash">sudo apt autoremovek</code></pre></div><p data-pid="7KZVQ-uj">接下来确定安装深度学习框架的版本。Nano上预装的Jetpack版本为4.6.1，Python为3.6.9，CUDA环境为10.2。计划安装目前更加流行的PyTorch库和配套的torchvision。由于Nano的处理器是aarch64架构，最好不要直接使用pypi库进行安装，需要在官网找预编译的whl文件或者从源码编译安装。</p><p data-pid="Yf1ACxf-">在官网的<a href="https://link.zhihu.com/?target=https%3A//developer.nvidia.com/embedded/downloads%23%3Fsearch%3Dpytorch" class=" wrap external" target="_blank" rel="nofollow noreferrer">Download Center</a>可以看到，支持JP4.6的只提供了torch1.11，不要被表象迷惑，因为我们去torchvision的<a href="https://link.zhihu.com/?target=https%3A//github.com/pytorch/vision/tree/release/0.11" class=" wrap external" target="_blank" rel="nofollow noreferrer">GitHub仓库</a>查看版本的兼容性，发现Python3.6+torch1.11没有任何torchvision的版本与之适配，要么需要升级Python，要么需要降级torch。我尝试过安装<a href="https://link.zhihu.com/?target=https%3A//github.com/Archiconda/build-tools/releases" class=" wrap external" target="_blank" rel="nofollow noreferrer">archiconda</a>来提升Python的版本，但出现了很多固有Bug，不太建议使用。</p><p data-pid="yAJkfthc">在论坛的帖子<a href="https://link.zhihu.com/?target=https%3A//forums.developer.nvidia.com/t/pytorch-for-jetson/72048" class=" wrap external" target="_blank" rel="nofollow noreferrer">PyTorch for Jetson</a>中可以找到更全面的torch版本，下载JP4下面的最高版本1.10即可：<a href="https://link.zhihu.com/?target=https%3A//nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl" class=" wrap external" target="_blank" rel="nofollow noreferrer">下载链接</a>。发现这里又声称1.10是JP4将会支持的最高版本，那刚刚那个1.11真的打脸。我们可以在Nano的远程终端wget下载，也可以在上位机下载好再使用scp或者U盘拷贝进去。</p><p data-pid="jevXyg1q">之后，需要pip工具来安装这个轮子，Nano默认不带pip，但是具备Python3.6.9的环境。</p><div class="highlight"><pre><code class="language-bash">sudo apt-get install python3-pip</code></pre></div><p data-pid="hm6R83LZ">然后替换清华镜像源（本地whl安装过程中也可能在线安装其他依赖库）。先使用mkdir创建~/.pip文件夹，然后修改pip.conf配置文件。</p><div class="highlight"><pre><code class="language-bash">vim ~/.pip/pip.conf
----------------------------------------------------
<span class="o">[</span>global<span class="o">]</span>
index-url <span class="o">=</span> https://pypi.tuna.tsinghua.edu.cn/simple
<span class="o">[</span>install<span class="o">]</span>
trusted-host <span class="o">=</span> https://pypi.tuna.tsinghua.edu.cn</code></pre></div><p data-pid="yQljYQVe">然后使用pip3安装本地的whl文件</p><div class="highlight"><pre><code class="language-bash">pip3 install torch-1.10.0-cp36-cp36m-linux_aarch64.whl</code></pre></div><p data-pid="y2bUYyPX">安装成功后进入Python3的shell导入验证一下</p><div class="highlight"><pre><code class="language-text">python3
-----------------------------------------------------------------------------
&gt;&gt;&gt; import torch
...
OSError: libomp.so: cannot open shared object file: No such file or directory</code></pre></div><p data-pid="l7rcusUn">报错告诉我们还需要安装依赖库libomp</p><div class="highlight"><pre><code class="language-bash">sudo apt-get install libomp5 libomp-dev</code></pre></div><p data-pid="Tqzj8v2M">再次验证出现</p><div class="highlight"><pre><code class="language-text">OSError: libmpi_cxx.so.20: cannot open shared object file: No such file or directory</code></pre></div><p data-pid="4bdSsVAv">安装依赖库openmpi2</p><div class="highlight"><pre><code class="language-bash">sudo apt-get install libopenmpi2</code></pre></div><p data-pid="6tizCo1N">再次验证出现</p><div class="highlight"><pre><code class="language-text">ImportError: libopenblas.so.0: cannot open shared object file: No such file or directory</code></pre></div><p data-pid="g_FP2rc7">安装依赖库openblas</p><div class="highlight"><pre><code class="language-bash">sudo apt-get install libopenblas-dev</code></pre></div><p data-pid="ppDNbdR9">再次验证发现Numpy的依赖警告</p><div class="highlight"><pre><code class="language-bash">UserWarning: Failed to initialize NumPy: No module named <span class="s1">&#39;numpy.core._multiarray_umath&#39;</span></code></pre></div><p data-pid="RyGcXOZd">参考网上的教程，我们需要安装低版本的Numpy库，在此之前需要安装Cython库</p><div class="highlight"><pre><code class="language-bash">pip3 install Cython
pip3 install <span class="nv">numpy</span><span class="o">==</span>1.19.1</code></pre></div><p data-pid="AN_6fP5D">这时需要等待较长的时间。之后进入shell导入torch库，并验证GPU的可用性</p><div class="highlight"><pre><code class="language-bash">python3
-----------------------------------------------------------------------------
&gt;&gt;&gt; import torch
&gt;&gt;&gt; torch.cuda.is_available<span class="o">()</span>
True</code></pre></div><h3>4.2 安装torchvision</h3><p data-pid="8A_fUmPw">在GitHub仓库提供的表格中找到与torch和python相适配的版本，在本文中是0.11.0。然后在左上角切换到对应的分支release/0.11。在Nano上下载该分支的源码</p><div class="highlight"><pre><code class="language-bash">git clone --branch release/0.11  https://github.com/pytorch/vision torchvision</code></pre></div><p data-pid="90kPz09J">进入torchvision目录，进行编译安装</p><div class="highlight"><pre><code class="language-bash"><span class="nb">cd</span> torchvision/
sudo python3 setup.py install</code></pre></div><p data-pid="1qbrTQO1">出现以下报错信息</p><div class="highlight"><pre><code class="language-text">The headers or library files could not be found for jpeg, a required dependency when compiling Pillow from source.</code></pre></div><p data-pid="zmvIZAmL">安装缺失的依赖库</p><div class="highlight"><pre><code class="language-bash">sudo apt-get install libjpeg-dev zlib1g-dev</code></pre></div><p data-pid="ZIwf6YRL">再次编译安装，等待很长一段时间，安装完成</p><div class="highlight"><pre><code class="language-text">...
Using /home/nvidia/.local/lib/python3.6/site-packages
Finished processing dependencies for torchvision==0.11.0a0+05eae32</code></pre></div><p data-pid="Vls0b25u">进入到Python的交互shell中import验证，发现Pillow库报错</p><div class="highlight"><pre><code class="language-text">File &#34;/usr/local/lib/python3.6/dist-packages/Pillow-9.5.0-py3.6-linux-aarch64.egg/PIL/_deprecate.py&#34;, line 1
SyntaxError: future feature annotations is not defined</code></pre></div><p data-pid="S524hiH6">很明显，annotation的语法是3.7才出现的，说明安装torchvision时引入的依赖库Pillow与Python版本不匹配，对其进行降级处理，参考<a href="https://link.zhihu.com/?target=https%3A//github.com/dusty-nv/jetson-inference/issues/1534" class=" wrap external" target="_blank" rel="nofollow noreferrer">issue</a>。</p><div class="highlight"><pre><code class="language-bash">pip3 install <span class="s1">&#39;pillow&lt;9&#39;</span></code></pre></div><p data-pid="TqTzNyBI">再次import验证，发现提示我们不要在torchvision的build目录下引入验证，可能会出现冲突</p><div class="highlight"><pre><code class="language-text">UserWarning: You are importing torchvision within its own root folder (/home/nvidia/Softwares/torchvision). This is not expected to work and may give errors. Please exit the torchvision project source and relaunch your python interpreter.</code></pre></div><p data-pid="QkVylD9v">返回上一级目录再次验证，发现成功导入。</p><h2>5 远程开发环境配置</h2><h3>5.1 配置VSCode远程连接</h3><p data-pid="SYMGqrCh">我平时常用的是PyCharm，但同学们貌似很中意VSCode，所以也尝试了在VSCode中配置远程开发环境，这里简要记录一下。</p><p data-pid="1rG9Hsv5">首先在VSCode中安装扩展插件Remote Development，其他的例如Remote - SSH，也是必要的，一般VSCode默认安装过。然后按F1搜索以下配置</p><div class="highlight"><pre><code class="language-text">Remote-SSH：Connect to Host-&gt;configure SSH Hosts-&gt;Settings(Specify a custom configure file)</code></pre></div><p data-pid="KTuPz9N5">在Config File这里输入路径C:/Users/用户名/.vscode_ssh/config（使用系统默认路径会和其他的SSH终端软件发生冲突，所以我们换了一个文件夹）。然后F1搜索以下配置</p><div class="highlight"><pre><code class="language-text">Remote-SSH：Connect to Host-&gt;configure SSH Hosts/C:/Users/用户名/.vscode_ssh/config</code></pre></div><p data-pid="0h0v9h76">编辑文件内容如下，HostName那里是Nano的IP地址</p><div class="highlight"><pre><code class="language-text">Host NanoXXX
    HostName 192.168.1.XXX
    User nvidia</code></pre></div><p data-pid="58Qhfw23">然后重启一下VSCode，可以在左侧远程资源管理器tab下看到刚刚配置的NanoXXX，点击上面的右箭头就可以连接远程环境了。首次连接会在Nano上安装VSCode Server。</p><h3>5.2 MNIST神经网络时延测试</h3><p data-pid="aYOkHdLx">在左侧资源管理器tab下打开Nano上的文件夹，创建python文件，写一个最简单的MNIST神经网络进行测试：</p><div class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda:0&#34;</span><span class="p">)</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))])</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data/mnist&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data/mnist&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calc_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">epoch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">running_acc</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">=</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">running_acc</span> <span class="o">+=</span> <span class="n">calc_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">running_loss</span> <span class="o">/=</span> <span class="n">total</span>
        <span class="n">running_acc</span> <span class="o">/=</span> <span class="n">total</span>
        <span class="n">testing_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%d</span><span class="s1">: TrainLoss </span><span class="si">%.6f</span><span class="s1">, TrainAcc </span><span class="si">%.4f</span><span class="s1">, TestAcc </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="n">epoch_idx</span><span class="p">,</span> <span class="n">running_loss</span><span class="p">,</span> <span class="n">running_acc</span><span class="p">,</span> <span class="n">testing_acc</span><span class="p">))</span>
        


<span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">testing_acc</span> <span class="o">=</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">testing_acc</span> <span class="o">+=</span> <span class="n">calc_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">testing_acc</span> <span class="o">/</span> <span class="n">total</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">beg_t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">train</span><span class="p">()</span>
    <span class="n">end_t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Elapsed Time Per Epoch: </span><span class="si">%.4f</span><span class="s2"> s&#34;</span> <span class="o">%</span> <span class="p">((</span><span class="n">end_t</span> <span class="o">-</span> <span class="n">beg_t</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_epochs</span><span class="p">))</span></code></pre></div><p data-pid="7WxA0JK3">在运行之前，先安装Jetson的性能监控工具，方便一会儿查看运行时资源消耗</p><div class="highlight"><pre><code class="language-bash">sudo -H pip3 install jetson-stats
sudo systemctl restart jtop.service</code></pre></div><p data-pid="5H4LAQH2">然后我们在VSCode编辑器的右上角点击运行按钮，选择Nano默认的Python解释器/usr/bin/python3。运行过程中，在SSH终端输入sudo jtop，看到以下画面</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-19730146d7e9e67e8af9a31f4ab459d7_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="1032" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://picx.zhimg.com/v2-19730146d7e9e67e8af9a31f4ab459d7_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1920&#39; height=&#39;1032&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1920" data-rawheight="1032" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://picx.zhimg.com/v2-19730146d7e9e67e8af9a31f4ab459d7_r.jpg" data-actualsrc="https://picx.zhimg.com/v2-19730146d7e9e67e8af9a31f4ab459d7_1440w.jpg" data-original-token="v2-7539779f611dab45a318768849ea0586"/></figure><p data-pid="qEXyuheV">VSCode终端的日志输出为</p><div class="highlight"><pre><code class="language-text">nvidia@nvidia-desktop:~/Workspace$ /usr/bin/python3 /home/nvidia/Workspace/test.py
Epoch 0: TrainLoss 0.162411, TrainAcc 0.9506, TestAcc 0.9850
Epoch 1: TrainLoss 0.057260, TrainAcc 0.9830, TestAcc 0.9842
Epoch 2: TrainLoss 0.042816, TrainAcc 0.9869, TestAcc 0.9893
Epoch 3: TrainLoss 0.036244, TrainAcc 0.9881, TestAcc 0.9872
Epoch 4: TrainLoss 0.028895, TrainAcc 0.9915, TestAcc 0.9891
Elapsed Time Per Epoch: 92.8100 s</code></pre></div><p data-pid="8mUU-pav">VSCode不太方便的地方是，程序貌似不接受我终端的KeyboardInterrupt，需要手动kill进程。安装完环境，跑完程序记得关机，尽量不要直接关电源，以防跑飞。使用命令</p><div class="highlight"><pre><code class="language-text">nvidia@nvidia-desktop:~$ sudo shutdown now
Connection to 192.168.1.XXX closed by remote host.
Connection to 192.168.1.XXX closed.</code></pre></div><p data-pid="rL_3N9Tr">除此之外，我也在其他机器上跑了一下MNIST的神经网络测试，对比如下（不包含下载数据集的时间）</p><table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><td>Jetson Nano B01 GPU</td><td>92.8100 s</td></tr><tr><td>华硕天选X PC CPU (i7-12700F)</td><td>12.4847 s</td></tr><tr><td>华硕天选X PC GPU (RTX 3060)</td><td>10.9913 s</td></tr><tr><td>华硕天选X PC GPU (RTX 3060 + BatchSize256)</td><td>06.5321 s</td></tr><tr><td>Colab GPU (T1)</td><td>20.3596 s</td></tr><tr><td>Colab CPU</td><td>29.4983 s</td></tr></tbody></table><p data-pid="Y3qcxP5G">Nano的慢不只是GPU慢，更在于TF卡的读写慢，内存、显存限制并行度，供电不足等等。希望上表能给大家一个速度上的直观感受，劝退一些在Nano上训练大模型的梦想。</p>