<blockquote data-pid="fXWY84zG">本文主要介绍NVIDIA Jetson Nano上的USB摄像头使用方法，包括拍照、m3u8网络视频流媒体分发、搭建RTP协议的视频直播以及捕鼠背景下的视频监控，也会介绍一些捕鼠经验</blockquote><h2>写在前面</h2><p data-pid="jC8OPPkz">最近实验室出现严重鼠患，老鼠偷吃了两箱牛奶、五根猫条、一袋榛子，啃坏了同学的眼镜盒和网线。它们四处游荡、昼伏夜出，虽然在多处布置的粘鼠板上留下了明显脚印，但从来没有真正地出现在人的视野中。向物业反馈多次无果，于是计划拍摄老鼠的真实照片，一方面在校园论坛中煽动恐惧、论坛治校，另一方面也方便分析老鼠的活动轨迹，制定更加科学的捕鼠陷阱。</p><p data-pid="ydNJeNh_">恰好手里有一台NVIDIA Jetson Nano和一个USB摄像头，于是想像火箭浣熊一样快速攒出一台监测老鼠的武器。我的思路很简单：夜晚实验室没人活动，也没有风，监控摄像头拍摄到的画面应当趋于静止，一旦有老鼠出没，就能检测到画面的变化，并进行抓拍。相应地，关掉拍摄位置的灯光，留下其他位置的灯光，制造一个相对黑暗的局部环境。</p><h2>设备参数</h2><p data-pid="CytURB1q">前一篇文章<a href="https://zhuanlan.zhihu.com/p/632057827" class="internal" target="_blank">NVIDIA Jetson Nano使用指南</a>介绍了Nano的基本使用方法，本文使用的还是同一个设备，即创乐博的Jetson Nano B01国产板（<a href="http://link.zhihu.com/?target=https%3A//item.m.jd.com/product/52914065067.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">京东商品详情页</a>）。上位机使用一台Win11系统的PC。</p><p data-pid="f-yfkV7b">Nano B01自带两个CSI摄像头接口，一般会搭载IMX219感光芯片的摄像头。但本文使用的是免驱USB接口的、感光芯片为OV2710的摄像头，内置麦克风，200万像素，100度视场角（<a href="http://link.zhihu.com/?target=https%3A//item.m.jd.com/product/10045488969525.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">京东商品详情页</a>）。本文将不会兼顾CSI摄像头的教程。大体思路类似，它们支持的编解码操作略有不同。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-b7cbf94836b15f6c6f90b8d327da4564_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="5792" data-rawheight="3256" class="origin_image zh-lightbox-thumb" width="5792" data-original="https://picx.zhimg.com/v2-b7cbf94836b15f6c6f90b8d327da4564_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='5792'%20height='3256'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="5792" data-rawheight="3256" class="origin_image zh-lightbox-thumb lazy" width="5792" data-original="https://picx.zhimg.com/v2-b7cbf94836b15f6c6f90b8d327da4564_720w.jpg?source=d16d100b" data-actualsrc="https://pic1.zhimg.com/v2-b7cbf94836b15f6c6f90b8d327da4564_720w.jpg?source=d16d100b"></figure><p data-pid="jMzRmK7G">这款摄像头可以通过镜头旋转来调整焦距，镜头长度范围据说是4毫米到12毫米。关于摄像头的焦距、景深的选择可以参考我此前的另一篇文章：<a href="https://zhuanlan.zhihu.com/p/389898700" class="internal" target="_blank">摄像机模型原理与内、外参数</a>。</p><p data-pid="faF1icf1">连接摄像头，给Nano上电，然后通过以下命令验证摄像头识别成功：</p><div class="highlight"><pre><code class="language-text"><span></span>ls /dev/video*
--------------
/dev/video0
</code></pre></div><p data-pid="1Rqa5wl4">接下来安装v4l-utils，一个摄像头管理工具（video for linux utilities）</p><div class="highlight"><pre><code class="language-text"><span></span>sudo apt install -y v4l-utils
</code></pre></div><p data-pid="qD9cot0l">安装成功后，执行以下命令检测已接入的摄像头</p><div class="highlight"><pre><code class="language-text"><span></span>v4l2-ctl --list-devices
</code></pre></div><p data-pid="bBPLEvCE">然后查看摄像头的具体信息，包括支持的分辨率、采集帧率和图像格式</p><div class="highlight"><pre><code class="language-text"><span></span>v4l2-ctl --device=/dev/video0 --list-formats-ext
--------------------------------------------------------
ioctl: VIDIOC_ENUM_FMT
        Index       : 0
        Type        : Video Capture
        Pixel Format: 'MJPG' (compressed)
        Name        : Motion-JPEG
                Size: Discrete 1920x1080
                        Interval: Discrete 0.033s (30.000 fps)
                        Interval: Discrete 0.040s (25.000 fps)
                        Interval: Discrete 0.050s (20.000 fps)
                        Interval: Discrete 0.067s (15.000 fps)
                        Interval: Discrete 0.100s (10.000 fps)
                        Interval: Discrete 0.200s (5.000 fps)
                Size: Discrete 1280x720
                        ...
                Size: Discrete 640x480
                        ...
                Size: Discrete 352x288
                        ...
                Size: Discrete 320x240
                        ...
                Size: Discrete 176x144
                        ...
                Size: Discrete 160x120
                        ...
                Size: Discrete 1920x1080
                        ...

        Index       : 1
        Type        : Video Capture
        Pixel Format: 'YUYV'
        Name        : YUYV 4:2:2
                Size: Discrete 640x480
                        Interval: Discrete 0.033s (30.000 fps)
                        Interval: Discrete 0.040s (25.000 fps)
                        Interval: Discrete 0.050s (20.000 fps)
                        Interval: Discrete 0.067s (15.000 fps)
                        Interval: Discrete 0.100s (10.000 fps)
                        Interval: Discrete 0.200s (5.000 fps)
                Size: Discrete 352x288
                        ...
                Size: Discrete 320x240
                        ...
                Size: Discrete 176x144
                        ...
                Size: Discrete 160x120
</code></pre></div><p data-pid="0qtC0znM">我们的摄像头支持MJPG和YUYV两种图像格式，在640x480的分辨率下每秒最多拍摄30帧，这个配置可以说相当拉了。</p><h2>拍照方法</h2><p data-pid="HXD3h6n8">有很多种方法，这里介绍两种。首先可以使用Python程序调用，需要使用pip3安装<a href="http://link.zhihu.com/?target=https%3A//github.com/thehapyone/NanoCamera" class=" wrap external" target="_blank" rel="nofollow noreferrer">NanoCamera</a>工具库。然后在代码中初始化一个摄像头实例：</p><div class="highlight"><pre><code class="language-python"><span></span><span class="kn">import</span> <span class="nn">nanocamera</span> <span class="k">as</span> <span class="nn">nc</span>
<span class="n">camera</span> <span class="o">=</span> <span class="n">nc</span><span class="o">.</span><span class="n">Camera</span><span class="p">(</span><span class="n">camera_type</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">640</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div><p data-pid="PITOONwL">其他参数都好理解，camera_type是摄像头类别，0代表CSI，1代表USB，2代表RTSP源，3代表IP/MJPEG源，2和3都是网络摄像头。现在我们调用拍照函数：</p><div class="highlight"><pre><code class="language-python"><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</code></pre></div><p data-pid="sWBO4Xkk">返回值将会是一个numpy.ndarray类型，可以使用PIL、OpenCV、Matplotlib等工具库进行可视化。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-504121d264a70ea17771282bdb8da3fa_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="590" data-rawheight="458" class="origin_image zh-lightbox-thumb" width="590" data-original="https://pica.zhimg.com/v2-504121d264a70ea17771282bdb8da3fa_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='590'%20height='458'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="590" data-rawheight="458" class="origin_image zh-lightbox-thumb lazy" width="590" data-original="https://pica.zhimg.com/v2-504121d264a70ea17771282bdb8da3fa_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-504121d264a70ea17771282bdb8da3fa_720w.jpg?source=d16d100b"></figure><p data-pid="FX3CoqJ5">另一种方法是，使用GStreamer，一个跨平台的多媒体框架。可以通过管道的方式拼接指定的组件，从而将多媒体处理的各个步骤串联起来。一个流程一般包括三个部分，依次是媒体的生产者src，过滤器filter和媒体的消费者sink，在官网的教程<a href="http://link.zhihu.com/?target=https%3A//gstreamer.freedesktop.org/documentation/tutorials/basic/concepts.html%3Fgi-language%3Dc" class=" wrap external" target="_blank" rel="nofollow noreferrer">Basic tutorial 2: GStreamer concepts</a>中有对这些概念的辨析。</p><p data-pid="vjrpuMYa">GStreamer除了可以作为程序的SDK，还提供了三个方便的命令行工具，其中最常用的就是gst-launch-1.0，这里提供了语法的说明：<a href="http://link.zhihu.com/?target=https%3A//gstreamer.freedesktop.org/documentation/tutorials/basic/gstreamer-tools.html%3Fgi-language%3Dc" class=" wrap external" target="_blank" rel="nofollow noreferrer">Basic tutorial 10: GStreamer tools</a>。使用这个命令组合多种组件，我们可以实现丰富的媒体处理功能。例如下面是拍照的命令，感叹号<code>!</code>隔开了不同的步骤，类似于管道中的<code>|</code> 。</p><div class="highlight"><pre><code class="language-bash"><span></span>gst-launch-1.0 v4l2src <span class="nv">device</span><span class="o">=</span>/dev/video0 io-mode<span class="o">=</span><span class="m">4</span> num-buffers<span class="o">=</span><span class="m">1</span> ! image/jpeg,format<span class="o">=</span>MJPG,width<span class="o">=</span><span class="m">1920</span>,height<span class="o">=</span><span class="m">1080</span> ! filesink <span class="nv">location</span><span class="o">=</span><span class="m">1</span>.jpeg
</code></pre></div><ul><li data-pid="qhb9jbCC">v4l2就是我们刚才安装的工具库，src代表它是生成媒体的源。后面跟着的是v4l2src的属性，参考<a href="http://link.zhihu.com/?target=https%3A//gstreamer.freedesktop.org/documentation/video4linux2/v4l2src.html%3Fgi-language%3Dc" class=" wrap external" target="_blank" rel="nofollow noreferrer">v4l2src文档</a>。其中device指定了设备所在的位置（我们知道linux系统将所有东西都抽象为文件，设备也不例外），io-mode是IO模式，是个枚举类型，4代表的是dmabuf，后面的num-buffers是父类的属性大概是说从src里取多少帧图像，我们取1帧即可。</li><li data-pid="2kQdsCDX">后面的image/jpeg叫做caps filter，格式看起来有点像Base64编码的开头，还有很多其他的格式，比如YUYV可能是摄像专用的图像，要使用video/x-raw。</li><li data-pid="p5Kum2L4">filesink就是将得到的媒体保存为文件，location指定了文件的位置。如果前面的caps filter是YUYV格式还需要经过JPEG编码，即前面要加上<code>!jpegenc</code>。 </li></ul><p data-pid="z-uNHgUq">ffmpeg也可以用来拍照、推流，但本文主要基于GStreamer。ffmpeg在Nano上需要使用专用的<a href="http://link.zhihu.com/?target=https%3A//github.com/jocover/jetson-ffmpeg" class=" wrap external" target="_blank" rel="nofollow noreferrer">jetson-ffmpeg</a>，安装起来比较麻烦，就没有尝试。</p><h2>视频流分发</h2><p data-pid="8fOiW4LA">首先在Nano上用Python开启一个HTTP文件服务器，比如我们当前在/home/nvidia/Workspace/video目录下</p><div class="highlight"><pre><code class="language-bash"><span></span>sudo nohup python3 -u -m http.server <span class="m">80</span> &gt;log <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">&amp;</span>
</code></pre></div><p data-pid="162SCyV9">直接用nohup提交需要sudo的命令会出错，因为nohup会忽略掉sudo的密码验证过程。我们可以先使用sudo ls，系统会要求我们输入密码。这时系统记录了一个session，一段时间内我们使用sudo是不需要密码的。然后再执行以上命令就成功在当前目录下开启了HTTP服务器，端口是80，地址是Nano的IP。</p><p data-pid="7rcr7zBG">之后使用以下命令创建推流的pipeline</p><div class="highlight"><pre><code class="language-bash"><span></span>gst-launch-1.0 v4l2src <span class="nv">device</span><span class="o">=</span>/dev/video0 ! nvjpegenc ! jpegparse ! multipartmux ! hlssink playlist-root<span class="o">=</span>http://192.168.1.109:80 <span class="nv">location</span><span class="o">=</span>/home/nvidia/Workspace/video/segment_%05d.ts max-files<span class="o">=</span><span class="m">10</span> target-duration<span class="o">=</span><span class="m">1</span>
--------------------------------------------------------------------------------------------------------------------------------
Setting pipeline to PAUSED ...
Pipeline is live and does not need PREROLL ...
Setting pipeline to PLAYING ...
New clock: GstSystemClock
</code></pre></div><p data-pid="C9swoXma">然后可以看到当前目录下出现了一个playlist.m3u8文件和逐渐变多的ts文件。我们设置了ts文件缓存的数量最多为10个，每个ts文件存储1s的视频。我们可以使用video.js构建HTML应用，把Nano作为视频源服务器，将web服务放在专门的服务器上。但是我们也可以用更简单的办法验证：在上位机上利用ffmpeg拉流。</p><p data-pid="jfCulrMo">如果平时经常搞爬虫，那么应该对ffmpeg下载流媒体并不陌生，这里省略windows安装ffmpeg的过程，大家自行百度即可。安装好后，我们在上位机的命令行输入以下指令：</p><div class="highlight"><pre><code class="language-text"><span></span>ffplay http://192.168.1.109/playlist.m3u8
</code></pre></div><p data-pid="I8vcy9vn">其中192.168.1.109是我的Nano的IP地址，需要替换一下。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-6cf01347f716fc0c3977aa494f720922_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1806" data-rawheight="578" class="origin_image zh-lightbox-thumb" width="1806" data-original="https://pic1.zhimg.com/v2-6cf01347f716fc0c3977aa494f720922_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1806'%20height='578'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1806" data-rawheight="578" class="origin_image zh-lightbox-thumb lazy" width="1806" data-original="https://pic1.zhimg.com/v2-6cf01347f716fc0c3977aa494f720922_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-6cf01347f716fc0c3977aa494f720922_720w.jpg?source=d16d100b"></figure><p data-pid="PC4BhIUE">能感受到明显的延迟（大概7、8秒），而且图像颜色出现了很大的问题，还不知道是什么原因。</p><h2>视频直播</h2><p data-pid="uRr1WZNx">之前的HLS方法是基于http协议的，它更适合录制好的视频做内容分发，类似于B站那样，一个视频被多个浏览器同时观看。当然，即使是分发也是很粗糙的方法，没有像DASH那样支持多码率的自适应。我们知道，一般想要收获更好的直播体验，会要求我们下载客户端而不是直接用浏览器观看，这样可以利用更快速的协议，比如RTP。</p><p data-pid="mlZE2oXP">这时我们已经不需要http服务器了，可以用ps -ef|grep server找到对应的进程ID，然后sudo kill -9杀掉进程。然后使用以下命令开启RTP推流：</p><div class="highlight"><pre><code class="language-bash"><span></span>gst-launch-1.0 v4l2src <span class="nv">device</span><span class="o">=</span>/dev/video0 io-mode<span class="o">=</span><span class="m">2</span> <span class="se">\</span>
! image/jpeg, <span class="nv">width</span><span class="o">=</span><span class="m">640</span>, <span class="nv">height</span><span class="o">=</span><span class="m">480</span>, <span class="nv">framerate</span><span class="o">=</span><span class="m">30</span>/1, <span class="nv">format</span><span class="o">=</span>MJPG  <span class="se">\</span>
! nvv4l2decoder <span class="nv">mjpeg</span><span class="o">=</span><span class="m">1</span> <span class="se">\</span>
! nvvidconv <span class="se">\</span>
! nvv4l2h264enc insert-sps-pps<span class="o">=</span><span class="nb">true</span> <span class="nv">bitrate</span><span class="o">=</span><span class="m">4000000</span> <span class="se">\</span>
! rtph264pay <span class="nv">pt</span><span class="o">=</span><span class="m">96</span> <span class="se">\</span>
! udpsink <span class="nv">port</span><span class="o">=</span><span class="m">5000</span> <span class="nv">host</span><span class="o">=</span><span class="m">192</span>.168.1.166
</code></pre></div><p data-pid="mERcQ6I_">这里有个极其关键的问题，而且大多数教程没有点明，就是最后的udpsink后面接的一定是上位机的IP而不是Nano自己的IP。之后我们需要在上位机下载一个支持打开远程RTP链接的下载器：<a href="http://link.zhihu.com/?target=https%3A//www.videolan.org/" class=" wrap external" target="_blank" rel="nofollow noreferrer">VLC</a>。</p><p data-pid="6SWbeH-K">然后我们在随便一个位置创建一个后缀为sdp的文件，比如stream.sdp，然后修改文件内容如下：</p><div class="highlight"><pre><code class="language-text"><span></span>m=video 5000 RTP/AVP 96
c=IN IP4 192.168.1.109
a=rtpmap:96 H264/90000
</code></pre></div><p data-pid="myWe1rvR">其中5000是和上面命令对应的Nano的UDP端口。下面的192.168.1.109是Nano的IP地址，整好和上面相反。然后96是载荷，和rtph264pay的pt参数一致（不需要修改）。保存之后，用VLC软件打开这个文件（如果装好了VLC，它将会是SDP文件的默认打开方式，直接双击就行）。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-a525de197f068d0bafeef2eab493d15a_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1928" data-rawheight="802" class="origin_image zh-lightbox-thumb" width="1928" data-original="https://picx.zhimg.com/v2-a525de197f068d0bafeef2eab493d15a_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1928'%20height='802'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1928" data-rawheight="802" class="origin_image zh-lightbox-thumb lazy" width="1928" data-original="https://picx.zhimg.com/v2-a525de197f068d0bafeef2eab493d15a_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-a525de197f068d0bafeef2eab493d15a_720w.jpg?source=d16d100b"></figure><p data-pid="koOT-Y5g">画面清晰正常，延迟下降到4~5秒。我猜想这是Nano的算力极限了。其实本文使用的这款摄像头也带有音频功能，是可以合在一起推流的，不过这部分实验我没做。</p><h2>捕鼠监控</h2><p data-pid="XZUGTK7-">老鼠喜欢在潮湿、黑暗、食物充足的地方活动。一般是昼伏夜出，嗅觉十分灵敏，隔着包装袋、纸箱都能找到食物：如果是大件，会就地啃开；如果是小件，一般会拖走，沿着墙根，拖到一个隐蔽、黑暗的地方慢慢吃。经验表明，在空旷明亮的环境下部署粘鼠板效果不好，因为老鼠很警觉，会试探性前进，而粘鼠板沾不住老鼠的脚。于是我们在墙根创造黑暗条件，在老鼠排泄物较多的地方部署了十个粘鼠板，然后挤上少量猫条作为诱饵。最后架设好摄像头对准其中一个位置的地面，然后开始编写算法逻辑。</p><p data-pid="y48rUIkF">Nano有诸多硬件资源约束，比如外存目前只剩下14GB左右。这个空间不足以存储整夜的监控视频或者高频抓拍的高分辨率图像。况且从冗长的视频中人工寻找老鼠出没的几帧非常耗时耗力。理想的状态是，摄像头对低分辨率视频进行实时过滤，仅当检测到画面内容变化时才触发存储功能。</p><p data-pid="CuXZj4Uv">对于画面内容变化的检测，其实就是帧相似度判别。我曾经拍脑袋想用像素的L1距离，结果发现不可行。摄像头有个特点，对周围环境很敏感，视场以外的东西遮挡了光线会导致画面内容不变，但颜色上整体偏移。比如我尝试用手遮挡摄像头，往往是手还没到，画面的色调就已经变得偏红。</p><p data-pid="HIXe_XaI">于是我想用方差的方式。先计算帧之间的逐像素差值向量x，然后让x减去x的均值，再计算绝对值的和。这样可以消除色调变化这种全局变化，捕捉局部变化。然而我后来发现环境光线的变化有时候也不是全局均匀作用的。查了下资料，发现还是使用余弦相似度更加合理，即</p><p data-pid="-_yQfcdB"><img src="https://www.zhihu.com/equation?tex=S%3D%5Cfrac%7BF_%7Bt-1%7D%5Ccdot+F_t%7D%7B%7CF_%7Bt-1%7D%7C%5Ctimes%7CF_t%7C%7D%5C%5C" alt="S=\frac{F_{t-1}\cdot F_t}{|F_{t-1}|\times|F_t|}\\" eeimg="1"> 把它封装成Python函数：</p><div class="highlight"><pre><code class="language-python"><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">linalg</span><span class="p">,</span> <span class="n">mean</span>

<span class="k">def</span> <span class="nf">calc_similarity</span><span class="p">(</span><span class="n">image_1</span><span class="p">,</span> <span class="n">image_2</span><span class="p">):</span>
    <span class="n">vec_1</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">image_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">vec_2</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">image_2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">vec_1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vec_2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec_1</span><span class="p">)</span> <span class="o">*</span> <span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec_2</span><span class="p">))</span>
</code></pre></div><p data-pid="Cwixf0mU">其中输入是两张numpy.ndarray格式的图片。输出是两张图片的相似度评分，数值范围在0~1之间，但是由于大多数像素是完全不变的，所以两张图片的相似度往往在0.99以上。接下来我们编写主控制逻辑</p><div class="highlight"><pre><code class="language-python"><span></span><span class="kn">import</span> <span class="nn">nanocamera</span> <span class="k">as</span> <span class="nn">nano</span>
<span class="kn">import</span> <span class="nn">cv2</span><span class="o">,</span> <span class="nn">time</span>


<span class="n">video</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">threshold</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="mf">0.99995</span><span class="p">,</span> <span class="mf">0.00005</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">video</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">delta</span>
    <span class="n">fourcc</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter_fourcc</span><span class="p">(</span><span class="o">*</span><span class="s1">'mp4v'</span><span class="p">)</span>
    <span class="n">camera</span> <span class="o">=</span> <span class="n">nano</span><span class="o">.</span><span class="n">Camera</span><span class="p">(</span><span class="n">camera_type</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">640</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">old_frame</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">new_video</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">stable_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">new_frame</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">similarity</span> <span class="o">=</span> <span class="n">calc_similarity</span><span class="p">(</span><span class="n">old_frame</span><span class="p">[::</span><span class="mi">10</span><span class="p">,</span> <span class="p">::</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">new_frame</span><span class="p">[::</span><span class="mi">10</span><span class="p">,</span> <span class="p">::</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="o">*</span> <span class="n">threshold</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="p">(</span><span class="n">similarity</span> <span class="o">-</span> <span class="n">delta</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">similarity</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">stable_counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">new_video</span><span class="p">:</span>
                <span class="n">video</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter</span><span class="p">(</span>
                    <span class="s2">"img/</span><span class="si">{}</span><span class="s2">.mp4"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">"%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S"</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">localtime</span><span class="p">())),</span> 
                    <span class="n">fourcc</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">480</span><span class="p">),</span> <span class="n">isColor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">new_video</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30</span> <span class="o">*</span> <span class="mi">2</span><span class="p">):</span>
                <span class="n">video</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stable_counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">new_video</span> <span class="ow">and</span> <span class="n">stable_counter</span> <span class="o">&gt;</span> <span class="mi">5</span><span class="p">:</span>
                <span class="n">video</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
                <span class="n">new_video</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"video_release at </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">"%Y-%m-</span><span class="si">%d</span><span class="s2"> %H:%M:%S"</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">localtime</span><span class="p">())))</span>
        <span class="n">old_frame</span> <span class="o">=</span> <span class="n">new_frame</span>
</code></pre></div><p data-pid="P44TM5-P">其中video动态地存储opencv中的VideoWriter对象，在帧间相似度小于阈值threshold时，如果new_video这个标志位为真，则新建一个实例，以当前的时间为文件名输出视频。其中fourcc是视频编码器，可选的并不多，这里配合mp4格式使用MP4V，如果是avi格式则要使用XVID。28代表的是存储的视频的帧率，这里我设了一个小于摄像头读取帧率（30FPS）的值，是考虑到程序真实的采集速度会比标称的更慢一些。</p><p data-pid="XmSjuXKC">当我们开始采集数据，就将new_video标志位置为假，意味着这一段时间内都复用已有的VideoWriter对象，而不需要创建新的。之后，我们循环60次，将大约2秒内采集的图像输出到视频文件中。</p><p data-pid="oagu7IK_">在上述过程中如果再次采集到的视频帧相似度重新超过阈值，意味着监控区域可能又趋于稳定，我们仍然不断进行2秒视频的采集，直到5次检查都认为是稳定的，则结束视频输出。通过video.release()释放软硬件资源。然后将new_video标志位置为真，也就是下次一旦出现变化就新建一个视频进行存储。</p><p data-pid="cP31R75n">可以注意到一些细节，比如在计算相似度之前，我们进行了10倍的下采样，用于加速相似度计算过程。我们使用滑动平均的方式确定阈值，保证阈值总是处于平均相似度以下0.00005的位置。在环境光线条件变化时，可能由于视频采集的噪点导致帧间相似度变化，我们的动态阈值可以很好地自适应这种变化。</p><p data-pid="Ugt7Cnug">环境的变化除了对相似度的均值造成影响，其实也会对其方差造成影响，即阈值的敏感性或者叫做视频帧的二阶差值敏感性。我没有考虑这种情况，因为逻辑上比较复杂，本文的代码在实际应用中已经有极其稳定的效果。</p><p data-pid="7YmusL0U">晚上写完算法之后去吃饭和打网球，这期间Nano从17:55到20:33连续运行了2小时38分钟，共检测到29个来往行人，能够完整捕捉行人从进入画面到走出画面的全过程，共使用存储空间21.1MB。以此类推，夜晚连续部署12小时最多只需要100MB以内的存储空间，方案可行。</p><figure data-size="normal"><noscript><img src="https://picx.zhimg.com/v2-af5700428ca98a32b883ca95190725e0_720w.jpg?source=d16d100b" data-caption="" data-size="normal" data-rawwidth="1409" data-rawheight="629" class="origin_image zh-lightbox-thumb" width="1409" data-original="https://pic1.zhimg.com/v2-af5700428ca98a32b883ca95190725e0_720w.jpg?source=d16d100b"></noscript><img src="data:image/svg+xml;utf8,&lt;svg%20xmlns='http://www.w3.org/2000/svg'%20width='1409'%20height='629'&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1409" data-rawheight="629" class="origin_image zh-lightbox-thumb lazy" width="1409" data-original="https://pic1.zhimg.com/v2-af5700428ca98a32b883ca95190725e0_720w.jpg?source=d16d100b" data-actualsrc="https://picx.zhimg.com/v2-af5700428ca98a32b883ca95190725e0_720w.jpg?source=d16d100b"></figure><p data-pid="sD2_lzQN">可惜的是，我晚上部署算法时太仓促，忘记将任务提交到后台，晚上10点半，在上位机息屏之后网络中断，任务自动结束。没有拍摄到老鼠画面，只拍摄到过往的同学。</p><p data-pid="iSz-s1G6">但庆幸的是，第二天早上发现粘鼠板成功捕获了两只Jerry，取得了捕鼠战役的首次大捷。事件发生在2023年6月1日，这篇文章是以回忆的方式重新梳理了一下当时的探索过程。</p>